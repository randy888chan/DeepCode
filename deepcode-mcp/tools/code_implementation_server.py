#!/usr/bin/env python3
"""
Code Implementation MCP Server - ä»£ç å®ç°MCPæœåŠ¡å™¨

è¿™ä¸ªMCPæœåŠ¡å™¨æä¾›äº†è®ºæ–‡ä»£ç å¤ç°æ‰€éœ€çš„æ ¸å¿ƒåŠŸèƒ½ï¼š
1. æ–‡ä»¶è¯»å†™æ“ä½œ (File read/write operations)
2. ä»£ç æ‰§è¡Œå’Œæµ‹è¯• (Code execution and testing)
3. ä»£ç æœç´¢å’Œåˆ†æ (Code search and analysis)
4. è¿­ä»£å¼æ”¹è¿›æ”¯æŒ (Iterative improvement support)

This MCP server provides core functions needed for paper code reproduction:
1. File read/write operations
2. Code execution and testing
3. Code search and analysis
4. Iterative improvement support

ä½¿ç”¨æ–¹æ³• / Usage:
python tools/code_implementation_server.py
"""

import os
import subprocess
import json
import sys
import io
from pathlib import Path
import re
from typing import Dict, Any
import tempfile
import shutil
import logging
from datetime import datetime

# è®¾ç½®æ ‡å‡†è¾“å‡ºç¼–ç ä¸ºUTF-8
if sys.stdout.encoding != "utf-8":
    try:
        if hasattr(sys.stdout, "reconfigure"):
            sys.stdout.reconfigure(encoding="utf-8")
            sys.stderr.reconfigure(encoding="utf-8")
        else:
            sys.stdout = io.TextIOWrapper(sys.stdout.detach(), encoding="utf-8")
            sys.stderr = io.TextIOWrapper(sys.stderr.detach(), encoding="utf-8")
    except Exception as e:
        print(f"Warning: Could not set UTF-8 encoding: {e}")

# å¯¼å…¥MCPç›¸å…³æ¨¡å—
from mcp.server.fastmcp import FastMCP

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# åˆ›å»ºFastMCPæœåŠ¡å™¨å®ä¾‹
mcp = FastMCP("code-implementation-server")

# å…¨å±€å˜é‡ï¼šå·¥ä½œç©ºé—´ç›®å½•å’Œæ“ä½œå†å²
WORKSPACE_DIR = None
OPERATION_HISTORY = []
CURRENT_FILES = {}


def initialize_workspace(workspace_dir: str = None):
    """åˆå§‹åŒ–å·¥ä½œç©ºé—´"""
    global WORKSPACE_DIR
    if workspace_dir is None:
        # é»˜è®¤ä½¿ç”¨å½“å‰ç›®å½•ä¸‹çš„generate_codeç›®å½•
        WORKSPACE_DIR = Path.cwd() / "generate_code"
    else:
        WORKSPACE_DIR = Path(workspace_dir).resolve()

    # ç¡®ä¿å·¥ä½œç©ºé—´ç›®å½•å­˜åœ¨
    WORKSPACE_DIR.mkdir(parents=True, exist_ok=True)
    logger.info(f"å·¥ä½œç©ºé—´åˆå§‹åŒ–: {WORKSPACE_DIR}")


def validate_path(path: str) -> Path:
    """éªŒè¯è·¯å¾„æ˜¯å¦åœ¨å·¥ä½œç©ºé—´å†…"""
    if WORKSPACE_DIR is None:
        initialize_workspace()

    full_path = (WORKSPACE_DIR / path).resolve()
    if not str(full_path).startswith(str(WORKSPACE_DIR)):
        raise ValueError(f"è·¯å¾„ {path} è¶…å‡ºå·¥ä½œç©ºé—´èŒƒå›´")
    return full_path


def log_operation(action: str, details: Dict[str, Any]):
    """è®°å½•æ“ä½œå†å²"""
    OPERATION_HISTORY.append(
        {"timestamp": datetime.now().isoformat(), "action": action, "details": details}
    )


# ==================== æ–‡ä»¶æ“ä½œå·¥å…· ====================


@mcp.tool()
async def read_file(
    file_path: str, start_line: int = None, end_line: int = None
) -> str:
    """
    è¯»å–æ–‡ä»¶å†…å®¹ï¼Œæ”¯æŒæŒ‡å®šè¡Œå·èŒƒå›´

    Args:
        file_path: æ–‡ä»¶è·¯å¾„ï¼Œç›¸å¯¹äºå·¥ä½œç©ºé—´
        start_line: èµ·å§‹è¡Œå·ï¼ˆä»1å¼€å§‹ï¼Œå¯é€‰ï¼‰
        end_line: ç»“æŸè¡Œå·ï¼ˆä»1å¼€å§‹ï¼Œå¯é€‰ï¼‰

    Returns:
        æ–‡ä»¶å†…å®¹æˆ–é”™è¯¯ä¿¡æ¯çš„JSONå­—ç¬¦ä¸²
    """
    try:
        full_path = validate_path(file_path)

        if not full_path.exists():
            result = {"status": "error", "message": f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}"}
            log_operation(
                "read_file_error", {"file_path": file_path, "error": "file_not_found"}
            )
            return json.dumps(result, ensure_ascii=False, indent=2)

        with open(full_path, "r", encoding="utf-8") as f:
            lines = f.readlines()

        # å¤„ç†è¡Œå·èŒƒå›´
        if start_line is not None or end_line is not None:
            start_idx = (start_line - 1) if start_line else 0
            end_idx = end_line if end_line else len(lines)
            lines = lines[start_idx:end_idx]

        content = "".join(lines)

        result = {
            "status": "success",
            "content": content,
            "file_path": file_path,
            "total_lines": len(lines),
            "size_bytes": len(content.encode("utf-8")),
        }

        log_operation(
            "read_file",
            {
                "file_path": file_path,
                "start_line": start_line,
                "end_line": end_line,
                "lines_read": len(lines),
            },
        )

        return json.dumps(result, ensure_ascii=False, indent=2)

    except Exception as e:
        result = {
            "status": "error",
            "message": f"è¯»å–æ–‡ä»¶å¤±è´¥: {str(e)}",
            "file_path": file_path,
        }
        log_operation("read_file_error", {"file_path": file_path, "error": str(e)})
        return json.dumps(result, ensure_ascii=False, indent=2)


@mcp.tool()
async def write_file(
    file_path: str, content: str, create_dirs: bool = True, create_backup: bool = False
) -> str:
    """
    å†™å…¥å†…å®¹åˆ°æ–‡ä»¶

    Args:
        file_path: æ–‡ä»¶è·¯å¾„ï¼Œç›¸å¯¹äºå·¥ä½œç©ºé—´
        content: è¦å†™å…¥çš„æ–‡ä»¶å†…å®¹
        create_dirs: å¦‚æœç›®å½•ä¸å­˜åœ¨æ˜¯å¦åˆ›å»º
        create_backup: å¦‚æœæ–‡ä»¶å·²å­˜åœ¨æ˜¯å¦åˆ›å»ºå¤‡ä»½æ–‡ä»¶

    Returns:
        æ“ä½œç»“æœçš„JSONå­—ç¬¦ä¸²
    """
    try:
        full_path = validate_path(file_path)

        # åˆ›å»ºç›®å½•ï¼ˆå¦‚æœéœ€è¦ï¼‰
        if create_dirs:
            full_path.parent.mkdir(parents=True, exist_ok=True)

        # å¤‡ä»½ç°æœ‰æ–‡ä»¶ï¼ˆä»…åœ¨æ˜ç¡®è¦æ±‚æ—¶ï¼‰
        backup_created = False
        if full_path.exists() and create_backup:
            backup_path = full_path.with_suffix(full_path.suffix + ".backup")
            shutil.copy2(full_path, backup_path)
            backup_created = True

        # å†™å…¥æ–‡ä»¶
        with open(full_path, "w", encoding="utf-8") as f:
            f.write(content)

        # æ›´æ–°å½“å‰æ–‡ä»¶è®°å½•
        CURRENT_FILES[file_path] = {
            "last_modified": datetime.now().isoformat(),
            "size_bytes": len(content.encode("utf-8")),
            "lines": len(content.split("\n")),
        }

        result = {
            "status": "success",
            "message": f"æ–‡ä»¶å†™å…¥æˆåŠŸ: {file_path}",
            "file_path": file_path,
            "size_bytes": len(content.encode("utf-8")),
            "lines_written": len(content.split("\n")),
            "backup_created": backup_created,
        }

        log_operation(
            "write_file",
            {
                "file_path": file_path,
                "size_bytes": len(content.encode("utf-8")),
                "lines": len(content.split("\n")),
                "backup_created": backup_created,
            },
        )

        return json.dumps(result, ensure_ascii=False, indent=2)

    except Exception as e:
        result = {
            "status": "error",
            "message": f"å†™å…¥æ–‡ä»¶å¤±è´¥: {str(e)}",
            "file_path": file_path,
        }
        log_operation("write_file_error", {"file_path": file_path, "error": str(e)})
        return json.dumps(result, ensure_ascii=False, indent=2)


# ==================== ä»£ç æ‰§è¡Œå·¥å…· ====================


@mcp.tool()
async def execute_python(code: str, timeout: int = 30) -> str:
    """
    æ‰§è¡ŒPythonä»£ç å¹¶è¿”å›è¾“å‡º

    Args:
        code: è¦æ‰§è¡Œçš„Pythonä»£ç 
        timeout: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰

    Returns:
        æ‰§è¡Œç»“æœçš„JSONå­—ç¬¦ä¸²
    """
    try:
        # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
        with tempfile.NamedTemporaryFile(
            mode="w", suffix=".py", delete=False, encoding="utf-8"
        ) as f:
            f.write(code)
            temp_file = f.name

        try:
            # æ‰§è¡ŒPythonä»£ç 
            result = subprocess.run(
                [sys.executable, temp_file],
                cwd=WORKSPACE_DIR,
                capture_output=True,
                text=True,
                timeout=timeout,
                encoding="utf-8",
            )

            execution_result = {
                "status": "success" if result.returncode == 0 else "error",
                "return_code": result.returncode,
                "stdout": result.stdout,
                "stderr": result.stderr,
                "timeout": timeout,
            }

            if result.returncode != 0:
                execution_result["message"] = "Pythonä»£ç æ‰§è¡Œå¤±è´¥"
            else:
                execution_result["message"] = "Pythonä»£ç æ‰§è¡ŒæˆåŠŸ"

            log_operation(
                "execute_python",
                {
                    "return_code": result.returncode,
                    "stdout_length": len(result.stdout),
                    "stderr_length": len(result.stderr),
                },
            )

            return json.dumps(execution_result, ensure_ascii=False, indent=2)

        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            os.unlink(temp_file)

    except subprocess.TimeoutExpired:
        result = {
            "status": "error",
            "message": f"Pythonä»£ç æ‰§è¡Œè¶…æ—¶ ({timeout}ç§’)",
            "timeout": timeout,
        }
        log_operation("execute_python_timeout", {"timeout": timeout})
        return json.dumps(result, ensure_ascii=False, indent=2)

    except Exception as e:
        result = {"status": "error", "message": f"Pythonä»£ç æ‰§è¡Œå¤±è´¥: {str(e)}"}
        log_operation("execute_python_error", {"error": str(e)})
        return json.dumps(result, ensure_ascii=False, indent=2)


@mcp.tool()
async def execute_bash(command: str, timeout: int = 30) -> str:
    """
    æ‰§è¡Œbashå‘½ä»¤

    Args:
        command: è¦æ‰§è¡Œçš„bashå‘½ä»¤
        timeout: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰

    Returns:
        æ‰§è¡Œç»“æœçš„JSONå­—ç¬¦ä¸²
    """
    try:
        # å®‰å…¨æ£€æŸ¥ï¼šç¦æ­¢å±é™©å‘½ä»¤
        dangerous_commands = ["rm -rf", "sudo", "chmod 777", "mkfs", "dd if="]
        if any(dangerous in command.lower() for dangerous in dangerous_commands):
            result = {"status": "error", "message": f"ç¦æ­¢æ‰§è¡Œå±é™©å‘½ä»¤: {command}"}
            log_operation(
                "execute_bash_blocked",
                {"command": command, "reason": "dangerous_command"},
            )
            return json.dumps(result, ensure_ascii=False, indent=2)

        # æ‰§è¡Œå‘½ä»¤
        result = subprocess.run(
            command,
            shell=True,
            cwd=WORKSPACE_DIR,
            capture_output=True,
            text=True,
            timeout=timeout,
            encoding="utf-8",
        )

        execution_result = {
            "status": "success" if result.returncode == 0 else "error",
            "return_code": result.returncode,
            "stdout": result.stdout,
            "stderr": result.stderr,
            "command": command,
            "timeout": timeout,
        }

        if result.returncode != 0:
            execution_result["message"] = "Bashå‘½ä»¤æ‰§è¡Œå¤±è´¥"
        else:
            execution_result["message"] = "Bashå‘½ä»¤æ‰§è¡ŒæˆåŠŸ"

        log_operation(
            "execute_bash",
            {
                "command": command,
                "return_code": result.returncode,
                "stdout_length": len(result.stdout),
                "stderr_length": len(result.stderr),
            },
        )

        return json.dumps(execution_result, ensure_ascii=False, indent=2)

    except subprocess.TimeoutExpired:
        result = {
            "status": "error",
            "message": f"Bashå‘½ä»¤æ‰§è¡Œè¶…æ—¶ ({timeout}ç§’)",
            "command": command,
            "timeout": timeout,
        }
        log_operation("execute_bash_timeout", {"command": command, "timeout": timeout})
        return json.dumps(result, ensure_ascii=False, indent=2)

    except Exception as e:
        result = {
            "status": "error",
            "message": f"Bashå‘½ä»¤æ‰§è¡Œå¤±è´¥: {str(e)}",
            "command": command,
        }
        log_operation("execute_bash_error", {"command": command, "error": str(e)})
        return json.dumps(result, ensure_ascii=False, indent=2)


# ==================== ä»£ç æœç´¢å·¥å…· ====================


@mcp.tool()
async def search_code(
    pattern: str, file_pattern: str = "*.py", use_regex: bool = False
) -> str:
    """
    åœ¨ä»£ç æ–‡ä»¶ä¸­æœç´¢æ¨¡å¼

    Args:
        pattern: æœç´¢æ¨¡å¼
        file_pattern: æ–‡ä»¶æ¨¡å¼ï¼ˆå¦‚ '*.py'ï¼‰
        use_regex: æ˜¯å¦ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼

    Returns:
        æœç´¢ç»“æœçš„JSONå­—ç¬¦ä¸²
    """
    try:
        if WORKSPACE_DIR is None:
            initialize_workspace()

        import glob

        # è·å–åŒ¹é…çš„æ–‡ä»¶
        file_paths = glob.glob(str(WORKSPACE_DIR / "**" / file_pattern), recursive=True)

        matches = []
        total_files_searched = 0

        for file_path in file_paths:
            try:
                with open(file_path, "r", encoding="utf-8") as f:
                    lines = f.readlines()

                total_files_searched += 1
                relative_path = os.path.relpath(file_path, WORKSPACE_DIR)

                for line_num, line in enumerate(lines, 1):
                    if use_regex:
                        if re.search(pattern, line):
                            matches.append(
                                {
                                    "file": relative_path,
                                    "line_number": line_num,
                                    "line_content": line.strip(),
                                    "match_type": "regex",
                                }
                            )
                    else:
                        if pattern.lower() in line.lower():
                            matches.append(
                                {
                                    "file": relative_path,
                                    "line_number": line_num,
                                    "line_content": line.strip(),
                                    "match_type": "substring",
                                }
                            )

            except Exception as e:
                logger.warning(f"æœç´¢æ–‡ä»¶æ—¶å‡ºé”™ {file_path}: {e}")
                continue

        result = {
            "status": "success",
            "pattern": pattern,
            "file_pattern": file_pattern,
            "use_regex": use_regex,
            "total_matches": len(matches),
            "total_files_searched": total_files_searched,
            "matches": matches[:50],  # é™åˆ¶è¿”å›å‰50ä¸ªåŒ¹é…
        }

        if len(matches) > 50:
            result["note"] = f"æ˜¾ç¤ºå‰50ä¸ªåŒ¹é…ï¼Œæ€»å…±æ‰¾åˆ°{len(matches)}ä¸ªåŒ¹é…"

        log_operation(
            "search_code",
            {
                "pattern": pattern,
                "file_pattern": file_pattern,
                "use_regex": use_regex,
                "total_matches": len(matches),
                "files_searched": total_files_searched,
            },
        )

        return json.dumps(result, ensure_ascii=False, indent=2)

    except Exception as e:
        result = {
            "status": "error",
            "message": f"ä»£ç æœç´¢å¤±è´¥: {str(e)}",
            "pattern": pattern,
        }
        log_operation("search_code_error", {"pattern": pattern, "error": str(e)})
        return json.dumps(result, ensure_ascii=False, indent=2)


# ==================== æ–‡ä»¶ç»“æ„å·¥å…· ====================


@mcp.tool()
async def get_file_structure(directory: str = ".", max_depth: int = 5) -> str:
    """
    è·å–ç›®å½•çš„æ–‡ä»¶ç»“æ„

    Args:
        directory: ç›®å½•è·¯å¾„ï¼Œç›¸å¯¹äºå·¥ä½œç©ºé—´
        max_depth: æœ€å¤§éå†æ·±åº¦

    Returns:
        æ–‡ä»¶ç»“æ„çš„JSONå­—ç¬¦ä¸²
    """
    try:
        if WORKSPACE_DIR is None:
            initialize_workspace()

        if directory == ".":
            target_dir = WORKSPACE_DIR
        else:
            target_dir = validate_path(directory)

        if not target_dir.exists():
            result = {"status": "error", "message": f"ç›®å½•ä¸å­˜åœ¨: {directory}"}
            return json.dumps(result, ensure_ascii=False, indent=2)

        def scan_directory(path: Path, current_depth: int = 0) -> Dict[str, Any]:
            """é€’å½’æ‰«æç›®å½•"""
            if current_depth >= max_depth:
                return {"type": "directory", "name": path.name, "truncated": True}

            items = []
            try:
                for item in sorted(path.iterdir()):
                    relative_path = os.path.relpath(item, WORKSPACE_DIR)

                    if item.is_file():
                        file_info = {
                            "type": "file",
                            "name": item.name,
                            "path": relative_path,
                            "size_bytes": item.stat().st_size,
                            "extension": item.suffix,
                        }
                        items.append(file_info)
                    elif item.is_dir() and not item.name.startswith("."):
                        dir_info = scan_directory(item, current_depth + 1)
                        dir_info["path"] = relative_path
                        items.append(dir_info)
            except PermissionError:
                pass

            return {
                "type": "directory",
                "name": path.name,
                "items": items,
                "item_count": len(items),
            }

        structure = scan_directory(target_dir)

        # ç»Ÿè®¡ä¿¡æ¯
        def count_items(node):
            if node["type"] == "file":
                return {"files": 1, "directories": 0}
            else:
                counts = {"files": 0, "directories": 1}
                for item in node.get("items", []):
                    item_counts = count_items(item)
                    counts["files"] += item_counts["files"]
                    counts["directories"] += item_counts["directories"]
                return counts

        counts = count_items(structure)

        result = {
            "status": "success",
            "directory": directory,
            "max_depth": max_depth,
            "structure": structure,
            "summary": {
                "total_files": counts["files"],
                "total_directories": counts["directories"] - 1,  # å‡å»æ ¹ç›®å½•
            },
        }

        log_operation(
            "get_file_structure",
            {
                "directory": directory,
                "max_depth": max_depth,
                "total_files": counts["files"],
                "total_directories": counts["directories"] - 1,
            },
        )

        return json.dumps(result, ensure_ascii=False, indent=2)

    except Exception as e:
        result = {
            "status": "error",
            "message": f"è·å–æ–‡ä»¶ç»“æ„å¤±è´¥: {str(e)}",
            "directory": directory,
        }
        log_operation(
            "get_file_structure_error", {"directory": directory, "error": str(e)}
        )
        return json.dumps(result, ensure_ascii=False, indent=2)


# ==================== å·¥ä½œç©ºé—´ç®¡ç†å·¥å…· ====================


@mcp.tool()
async def set_workspace(workspace_path: str) -> str:
    """
    è®¾ç½®å·¥ä½œç©ºé—´ç›®å½•

    Args:
        workspace_path: å·¥ä½œç©ºé—´è·¯å¾„

    Returns:
        æ“ä½œç»“æœçš„JSONå­—ç¬¦ä¸²
    """
    try:
        global WORKSPACE_DIR
        new_workspace = Path(workspace_path).resolve()

        # åˆ›å»ºç›®å½•ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
        new_workspace.mkdir(parents=True, exist_ok=True)

        old_workspace = WORKSPACE_DIR
        WORKSPACE_DIR = new_workspace

        result = {
            "status": "success",
            "message": f"å·¥ä½œç©ºé—´è®¾ç½®æˆåŠŸ: {workspace_path}",
            "old_workspace": str(old_workspace) if old_workspace else None,
            "new_workspace": str(WORKSPACE_DIR),
        }

        log_operation(
            "set_workspace",
            {
                "old_workspace": str(old_workspace) if old_workspace else None,
                "new_workspace": str(WORKSPACE_DIR),
            },
        )

        return json.dumps(result, ensure_ascii=False, indent=2)

    except Exception as e:
        result = {
            "status": "error",
            "message": f"è®¾ç½®å·¥ä½œç©ºé—´å¤±è´¥: {str(e)}",
            "workspace_path": workspace_path,
        }
        log_operation(
            "set_workspace_error", {"workspace_path": workspace_path, "error": str(e)}
        )
        return json.dumps(result, ensure_ascii=False, indent=2)


@mcp.tool()
async def get_operation_history(last_n: int = 10) -> str:
    """
    è·å–æ“ä½œå†å²

    Args:
        last_n: è¿”å›æœ€è¿‘çš„Nä¸ªæ“ä½œ

    Returns:
        æ“ä½œå†å²çš„JSONå­—ç¬¦ä¸²
    """
    try:
        recent_history = (
            OPERATION_HISTORY[-last_n:] if last_n > 0 else OPERATION_HISTORY
        )

        result = {
            "status": "success",
            "total_operations": len(OPERATION_HISTORY),
            "returned_operations": len(recent_history),
            "workspace": str(WORKSPACE_DIR) if WORKSPACE_DIR else None,
            "history": recent_history,
        }

        return json.dumps(result, ensure_ascii=False, indent=2)

    except Exception as e:
        result = {"status": "error", "message": f"è·å–æ“ä½œå†å²å¤±è´¥: {str(e)}"}
        return json.dumps(result, ensure_ascii=False, indent=2)


# ==================== æœåŠ¡å™¨åˆå§‹åŒ– ====================


def main():
    """å¯åŠ¨MCPæœåŠ¡å™¨"""
    print("ğŸš€ Code Implementation MCP Server")
    print("ğŸ“ è®ºæ–‡ä»£ç å¤ç°å·¥å…·æœåŠ¡å™¨ / Paper Code Implementation Tool Server")
    print("")
    print("Available tools / å¯ç”¨å·¥å…·:")
    print("  â€¢ read_file           - è¯»å–æ–‡ä»¶å†…å®¹ / Read file contents")
    print("  â€¢ write_file          - å†™å…¥æ–‡ä»¶å†…å®¹ / Write file contents")
    print("  â€¢ execute_python      - æ‰§è¡ŒPythonä»£ç  / Execute Python code")
    print("  â€¢ execute_bash        - æ‰§è¡Œbashå‘½ä»¤ / Execute bash commands")
    print("  â€¢ search_code         - æœç´¢ä»£ç æ¨¡å¼ / Search code patterns")
    print("  â€¢ get_file_structure  - è·å–æ–‡ä»¶ç»“æ„ / Get file structure")
    print("  â€¢ set_workspace       - è®¾ç½®å·¥ä½œç©ºé—´ / Set workspace")
    print("  â€¢ get_operation_history - è·å–æ“ä½œå†å² / Get operation history")
    print("")
    print("ğŸ”§ Server starting...")

    # åˆå§‹åŒ–é»˜è®¤å·¥ä½œç©ºé—´
    initialize_workspace()

    # å¯åŠ¨æœåŠ¡å™¨
    mcp.run()


if __name__ == "__main__":
    main()
