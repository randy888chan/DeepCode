#!/usr/bin/env python3
"""
Code Reference Indexer MCP Tool - ä»£ç å‚è€ƒç´¢å¼•å™¨ MCP å·¥å…·

ä¸“é—¨è´Ÿè´£åœ¨indexesæ–‡ä»¶å¤¹ä¸­æœç´¢ç›¸å…³çš„indexå†…å®¹ï¼Œå¹¶æ•´ç†æ ¼å¼åŒ–æä¾›ç»™LLMç”¨äºä»£ç å®ç°å‚è€ƒ
Specialized in searching relevant index content in indexes folder and formatting it for LLM code implementation reference

æ ¸å¿ƒåŠŸèƒ½ï¼š
1. æœç´¢indexesæ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰JSONæ–‡ä»¶
2. æ ¹æ®ç›®æ ‡æ–‡ä»¶è·¯å¾„å’ŒåŠŸèƒ½éœ€æ±‚åŒ¹é…ç›¸å…³çš„å‚è€ƒä»£ç 
3. æ ¼å¼åŒ–è¾“å‡ºç›¸å…³çš„ä»£ç ç¤ºä¾‹ã€å‡½æ•°å’Œæ¦‚å¿µ
4. æä¾›ç»“æ„åŒ–çš„å‚è€ƒä¿¡æ¯ä¾›LLMä½¿ç”¨

Core Features:
1. Search all JSON files in indexes folder
2. Match relevant reference code based on target file path and functionality requirements
3. Format output of relevant code examples, functions and concepts
4. Provide structured reference information for LLM use
"""

import os
import json
import re
from pathlib import Path
from typing import Dict, Any, List, Optional, Tuple
from dataclasses import dataclass
from collections import defaultdict
import logging

# å¯¼å…¥MCPç›¸å…³æ¨¡å—
from mcp.server.fastmcp import FastMCP
import mcp.types as types

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# åˆ›å»ºFastMCPæœåŠ¡å™¨å®ä¾‹
mcp = FastMCP("code-reference-indexer")

# å…¨å±€å˜é‡ï¼šç´¢å¼•ç¼“å­˜
INDEX_CACHE = {}
INDEXES_DIRECTORY = None


@dataclass
class CodeReference:
    """ä»£ç å‚è€ƒä¿¡æ¯ç»“æ„"""
    file_path: str
    file_type: str
    main_functions: List[str]
    key_concepts: List[str]
    dependencies: List[str]
    summary: str
    lines_of_code: int
    repo_name: str
    confidence_score: float = 0.0


@dataclass
class RelationshipInfo:
    """å…³ç³»ä¿¡æ¯ç»“æ„"""
    repo_file_path: str
    target_file_path: str
    relationship_type: str
    confidence_score: float
    helpful_aspects: List[str]
    potential_contributions: List[str]
    usage_suggestions: str


def initialize_indexes_directory(indexes_dir: str = None):
    """åˆå§‹åŒ–ç´¢å¼•ç›®å½•"""
    global INDEXES_DIRECTORY
    if indexes_dir is None:
        # é»˜è®¤æŸ¥æ‰¾agent_folders/papers/1/indexesç›®å½•
        current_dir = Path.cwd()
        INDEXES_DIRECTORY = current_dir / "agent_folders" / "papers" / "1" / "indexes"
    else:
        INDEXES_DIRECTORY = Path(indexes_dir).resolve()
    
    if not INDEXES_DIRECTORY.exists():
        logger.warning(f"ç´¢å¼•ç›®å½•ä¸å­˜åœ¨: {INDEXES_DIRECTORY}")
    else:
        logger.info(f"ç´¢å¼•ç›®å½•åˆå§‹åŒ–: {INDEXES_DIRECTORY}")


def load_index_files() -> Dict[str, Dict]:
    """åŠ è½½æ‰€æœ‰ç´¢å¼•æ–‡ä»¶åˆ°ç¼“å­˜"""
    global INDEX_CACHE
    
    if INDEXES_DIRECTORY is None:
        initialize_indexes_directory()
    
    if not INDEXES_DIRECTORY.exists():
        return {}
    
    INDEX_CACHE = {}
    
    for index_file in INDEXES_DIRECTORY.glob("*.json"):
        try:
            with open(index_file, 'r', encoding='utf-8') as f:
                index_data = json.load(f)
                INDEX_CACHE[index_file.stem] = index_data
                logger.info(f"åŠ è½½ç´¢å¼•æ–‡ä»¶: {index_file.name}")
        except Exception as e:
            logger.error(f"åŠ è½½ç´¢å¼•æ–‡ä»¶å¤±è´¥ {index_file.name}: {e}")
    
    return INDEX_CACHE


def extract_code_references(index_data: Dict) -> List[CodeReference]:
    """ä»ç´¢å¼•æ•°æ®ä¸­æå–ä»£ç å‚è€ƒä¿¡æ¯"""
    references = []
    
    repo_name = index_data.get("repo_name", "Unknown")
    file_summaries = index_data.get("file_summaries", [])
    
    for file_summary in file_summaries:
        reference = CodeReference(
            file_path=file_summary.get("file_path", ""),
            file_type=file_summary.get("file_type", ""),
            main_functions=file_summary.get("main_functions", []),
            key_concepts=file_summary.get("key_concepts", []),
            dependencies=file_summary.get("dependencies", []),
            summary=file_summary.get("summary", ""),
            lines_of_code=file_summary.get("lines_of_code", 0),
            repo_name=repo_name
        )
        references.append(reference)
    
    return references


def extract_relationships(index_data: Dict) -> List[RelationshipInfo]:
    """ä»ç´¢å¼•æ•°æ®ä¸­æå–å…³ç³»ä¿¡æ¯"""
    relationships = []
    
    relationship_list = index_data.get("relationships", [])
    
    for rel in relationship_list:
        relationship = RelationshipInfo(
            repo_file_path=rel.get("repo_file_path", ""),
            target_file_path=rel.get("target_file_path", ""),
            relationship_type=rel.get("relationship_type", ""),
            confidence_score=rel.get("confidence_score", 0.0),
            helpful_aspects=rel.get("helpful_aspects", []),
            potential_contributions=rel.get("potential_contributions", []),
            usage_suggestions=rel.get("usage_suggestions", "")
        )
        relationships.append(relationship)
    
    return relationships


def calculate_relevance_score(target_file: str, reference: CodeReference, keywords: List[str] = None) -> float:
    """è®¡ç®—å‚è€ƒä»£ç ä¸ç›®æ ‡æ–‡ä»¶çš„ç›¸å…³æ€§å¾—åˆ†"""
    score = 0.0
    
    # æ–‡ä»¶åç›¸ä¼¼æ€§
    target_name = Path(target_file).stem.lower()
    ref_name = Path(reference.file_path).stem.lower()
    
    if target_name in ref_name or ref_name in target_name:
        score += 0.3
    
    # æ–‡ä»¶ç±»å‹åŒ¹é…
    target_extension = Path(target_file).suffix
    ref_extension = Path(reference.file_path).suffix
    
    if target_extension == ref_extension:
        score += 0.2
    
    # å…³é”®è¯åŒ¹é…
    if keywords:
        keyword_matches = 0
        total_searchable_text = (
            " ".join(reference.key_concepts) + " " +
            " ".join(reference.main_functions) + " " +
            reference.summary + " " +
            reference.file_type
        ).lower()
        
        for keyword in keywords:
            if keyword.lower() in total_searchable_text:
                keyword_matches += 1
        
        if keywords:
            score += (keyword_matches / len(keywords)) * 0.5
    
    return min(score, 1.0)


def find_relevant_references(
    target_file: str, 
    keywords: List[str] = None, 
    max_results: int = 10
) -> List[Tuple[CodeReference, float]]:
    """æŸ¥æ‰¾ä¸ç›®æ ‡æ–‡ä»¶ç›¸å…³çš„å‚è€ƒä»£ç """
    if not INDEX_CACHE:
        load_index_files()
    
    all_references = []
    
    # ä»æ‰€æœ‰ç´¢å¼•æ–‡ä»¶ä¸­æ”¶é›†å‚è€ƒä¿¡æ¯
    for repo_name, index_data in INDEX_CACHE.items():
        references = extract_code_references(index_data)
        for ref in references:
            relevance_score = calculate_relevance_score(target_file, ref, keywords)
            if relevance_score > 0.1:  # åªä¿ç•™æœ‰ä¸€å®šç›¸å…³æ€§çš„ç»“æœ
                all_references.append((ref, relevance_score))
    
    # æŒ‰ç›¸å…³æ€§å¾—åˆ†æ’åº
    all_references.sort(key=lambda x: x[1], reverse=True)
    
    return all_references[:max_results]


def find_direct_relationships(target_file: str) -> List[RelationshipInfo]:
    """æŸ¥æ‰¾ä¸ç›®æ ‡æ–‡ä»¶çš„ç›´æ¥å…³ç³»"""
    if not INDEX_CACHE:
        load_index_files()
    
    relationships = []
    
    # æ ‡å‡†åŒ–ç›®æ ‡æ–‡ä»¶è·¯å¾„ï¼ˆç§»é™¤å‰ç¼€rice/å¦‚æœå­˜åœ¨ï¼‰
    normalized_target = target_file.replace("rice/", "").strip("/")
    
    # ä»æ‰€æœ‰ç´¢å¼•æ–‡ä»¶ä¸­æ”¶é›†å…³ç³»ä¿¡æ¯
    for repo_name, index_data in INDEX_CACHE.items():
        repo_relationships = extract_relationships(index_data)
        for rel in repo_relationships:
            # æ ‡å‡†åŒ–å…³ç³»ä¸­çš„ç›®æ ‡æ–‡ä»¶è·¯å¾„
            normalized_rel_target = rel.target_file_path.replace("rice/", "").strip("/")
            
            # æ£€æŸ¥ç›®æ ‡æ–‡ä»¶è·¯å¾„åŒ¹é…ï¼ˆæ”¯æŒå¤šç§åŒ¹é…æ–¹å¼ï¼‰
            if (normalized_target == normalized_rel_target or 
                normalized_target in normalized_rel_target or 
                normalized_rel_target in normalized_target or
                target_file in rel.target_file_path or 
                rel.target_file_path in target_file):
                relationships.append(rel)
    
    # æŒ‰ç½®ä¿¡åº¦æ’åº
    relationships.sort(key=lambda x: x.confidence_score, reverse=True)
    
    return relationships


def format_reference_output(
    target_file: str,
    relevant_refs: List[Tuple[CodeReference, float]],
    relationships: List[RelationshipInfo]
) -> str:
    """æ ¼å¼åŒ–å‚è€ƒä¿¡æ¯è¾“å‡º"""
    output_lines = []
    
    output_lines.append(f"# ä»£ç å‚è€ƒä¿¡æ¯ - {target_file}")
    output_lines.append("=" * 80)
    output_lines.append("")
    
    # ç›´æ¥å…³ç³»ä¿¡æ¯
    if relationships:
        output_lines.append("## ğŸ¯ ç›´æ¥å…³ç³»å‚è€ƒ (Direct Relationships)")
        output_lines.append("")
        
        for i, rel in enumerate(relationships[:5], 1):
            output_lines.append(f"### {i}. {rel.repo_file_path}")
            output_lines.append(f"**å…³ç³»ç±»å‹**: {rel.relationship_type}")
            output_lines.append(f"**ç½®ä¿¡åº¦**: {rel.confidence_score:.2f}")
            output_lines.append(f"**æœ‰ç”¨æ–¹é¢**: {', '.join(rel.helpful_aspects)}")
            output_lines.append(f"**æ½œåœ¨è´¡çŒ®**: {', '.join(rel.potential_contributions)}")
            output_lines.append(f"**ä½¿ç”¨å»ºè®®**: {rel.usage_suggestions}")
            output_lines.append("")
    
    # ç›¸å…³ä»£ç å‚è€ƒ
    if relevant_refs:
        output_lines.append("## ğŸ“š ç›¸å…³ä»£ç å‚è€ƒ (Relevant Code References)")
        output_lines.append("")
        
        for i, (ref, score) in enumerate(relevant_refs[:8], 1):
            output_lines.append(f"### {i}. {ref.file_path} (ç›¸å…³æ€§: {score:.2f})")
            output_lines.append(f"**ä»“åº“**: {ref.repo_name}")
            output_lines.append(f"**æ–‡ä»¶ç±»å‹**: {ref.file_type}")
            output_lines.append(f"**ä¸»è¦å‡½æ•°**: {', '.join(ref.main_functions[:5])}")
            output_lines.append(f"**å…³é”®æ¦‚å¿µ**: {', '.join(ref.key_concepts[:8])}")
            output_lines.append(f"**ä¾èµ–**: {', '.join(ref.dependencies[:6])}")
            output_lines.append(f"**ä»£ç è¡Œæ•°**: {ref.lines_of_code}")
            output_lines.append(f"**æ‘˜è¦**: {ref.summary[:300]}...")
            output_lines.append("")
    
    # å®ç°å»ºè®®
    output_lines.append("## ğŸ’¡ å®ç°å»ºè®® (Implementation Suggestions)")
    output_lines.append("")
    
    if relevant_refs:
        # æ”¶é›†æ‰€æœ‰å‡½æ•°åå’Œæ¦‚å¿µ
        all_functions = set()
        all_concepts = set()
        all_dependencies = set()
        
        for ref, _ in relevant_refs[:5]:
            all_functions.update(ref.main_functions)
            all_concepts.update(ref.key_concepts)
            all_dependencies.update(ref.dependencies)
        
        output_lines.append("**å¯å‚è€ƒçš„å‡½æ•°åæ¨¡å¼**:")
        for func in sorted(list(all_functions))[:10]:
            output_lines.append(f"- {func}")
        output_lines.append("")
        
        output_lines.append("**é‡è¦æ¦‚å¿µå’Œæ¨¡å¼**:")
        for concept in sorted(list(all_concepts))[:15]:
            output_lines.append(f"- {concept}")
        output_lines.append("")
        
        output_lines.append("**å¯èƒ½éœ€è¦çš„ä¾èµ–**:")
        for dep in sorted(list(all_dependencies))[:10]:
            output_lines.append(f"- {dep}")
        output_lines.append("")
    
    output_lines.append("## ğŸš€ ä¸‹ä¸€æ­¥è¡ŒåŠ¨ (Next Actions)")
    output_lines.append("1. åˆ†æä»¥ä¸Šå‚è€ƒä»£ç çš„è®¾è®¡æ¨¡å¼å’Œæ¶æ„é£æ ¼")
    output_lines.append("2. ç¡®å®šéœ€è¦å®ç°çš„æ ¸å¿ƒåŠŸèƒ½å’Œæ¥å£")
    output_lines.append("3. é€‰æ‹©åˆé€‚çš„ä¾èµ–åº“å’Œå·¥å…·")
    output_lines.append("4. è®¾è®¡ä¸ç°æœ‰ä»£ç é£æ ¼ä¸€è‡´çš„å®ç°æ–¹æ¡ˆ")
    output_lines.append("5. å¼€å§‹ç¼–å†™å…·ä½“çš„ä»£ç å®ç°")
    
    return "\n".join(output_lines)


# ==================== MCPå·¥å…·å®šä¹‰ ====================

@mcp.tool()
async def search_reference_code(
    target_file: str,
    keywords: str = "",
    max_results: int = 10
) -> str:
    """
    åœ¨ç´¢å¼•æ–‡ä»¶ä¸­æœç´¢ä¸ç›®æ ‡æ–‡ä»¶ç›¸å…³çš„å‚è€ƒä»£ç 
    
    Args:
        target_file: ç›®æ ‡æ–‡ä»¶è·¯å¾„ï¼ˆè¦å®ç°çš„æ–‡ä»¶ï¼‰
        keywords: æœç´¢å…³é”®è¯ï¼Œç”¨é€—å·åˆ†éš”
        max_results: æœ€å¤§è¿”å›ç»“æœæ•°é‡
    
    Returns:
        æ ¼å¼åŒ–çš„å‚è€ƒä»£ç ä¿¡æ¯JSONå­—ç¬¦ä¸²
    """
    try:
        # è§£æå…³é”®è¯
        keyword_list = [kw.strip() for kw in keywords.split(",") if kw.strip()] if keywords else []
        
        # æŸ¥æ‰¾ç›¸å…³å‚è€ƒä»£ç 
        relevant_refs = find_relevant_references(target_file, keyword_list, max_results)
        
        # æŸ¥æ‰¾ç›´æ¥å…³ç³»
        relationships = find_direct_relationships(target_file)
        
        # æ ¼å¼åŒ–è¾“å‡º
        formatted_output = format_reference_output(target_file, relevant_refs, relationships)
        
        result = {
            "status": "success",
            "target_file": target_file,
            "keywords_used": keyword_list,
            "total_references_found": len(relevant_refs),
            "total_relationships_found": len(relationships),
            "formatted_content": formatted_output,
            "indexes_loaded": list(INDEX_CACHE.keys())
        }
        
        return json.dumps(result, ensure_ascii=False, indent=2)
        
    except Exception as e:
        result = {
            "status": "error",
            "message": f"æœç´¢å‚è€ƒä»£ç å¤±è´¥: {str(e)}",
            "target_file": target_file
        }
        return json.dumps(result, ensure_ascii=False, indent=2)


@mcp.tool()
async def get_all_available_references() -> str:
    """
    è·å–æ‰€æœ‰å¯ç”¨çš„å‚è€ƒä»£ç ç´¢å¼•ä¿¡æ¯
    
    Returns:
        æ‰€æœ‰å¯ç”¨å‚è€ƒä»£ç çš„æ¦‚è§ˆä¿¡æ¯JSONå­—ç¬¦ä¸²
    """
    try:
        if not INDEX_CACHE:
            load_index_files()
        
        overview = {
            "total_repos": len(INDEX_CACHE),
            "repositories": {}
        }
        
        for repo_name, index_data in INDEX_CACHE.items():
            repo_info = {
                "repo_name": index_data.get("repo_name", repo_name),
                "total_files": index_data.get("total_files", 0),
                "file_types": [],
                "main_concepts": [],
                "total_relationships": len(index_data.get("relationships", []))
            }
            
            # æ”¶é›†æ–‡ä»¶ç±»å‹å’Œæ¦‚å¿µ
            file_summaries = index_data.get("file_summaries", [])
            file_types = set()
            concepts = set()
            
            for file_summary in file_summaries:
                file_types.add(file_summary.get("file_type", "Unknown"))
                concepts.update(file_summary.get("key_concepts", []))
            
            repo_info["file_types"] = sorted(list(file_types))
            repo_info["main_concepts"] = sorted(list(concepts))[:20]  # é™åˆ¶æ¦‚å¿µæ•°é‡
            
            overview["repositories"][repo_name] = repo_info
        
        result = {
            "status": "success",
            "overview": overview,
            "indexes_directory": str(INDEXES_DIRECTORY) if INDEXES_DIRECTORY else "Not set"
        }
        
        return json.dumps(result, ensure_ascii=False, indent=2)
        
    except Exception as e:
        result = {
            "status": "error",
            "message": f"è·å–å‚è€ƒä»£ç æ¦‚è§ˆå¤±è´¥: {str(e)}"
        }
        return json.dumps(result, ensure_ascii=False, indent=2)


@mcp.tool()
async def set_indexes_directory(indexes_path: str) -> str:
    """
    è®¾ç½®ç´¢å¼•æ–‡ä»¶ç›®å½•è·¯å¾„
    
    Args:
        indexes_path: ç´¢å¼•æ–‡ä»¶ç›®å½•è·¯å¾„
    
    Returns:
        è®¾ç½®ç»“æœçš„JSONå­—ç¬¦ä¸²
    """
    try:
        global INDEXES_DIRECTORY, INDEX_CACHE
        
        INDEXES_DIRECTORY = Path(indexes_path).resolve()
        
        if not INDEXES_DIRECTORY.exists():
            result = {
                "status": "error",
                "message": f"ç´¢å¼•ç›®å½•ä¸å­˜åœ¨: {indexes_path}"
            }
        else:
            # é‡æ–°åŠ è½½ç´¢å¼•æ–‡ä»¶
            INDEX_CACHE = {}
            load_index_files()
            
            result = {
                "status": "success",
                "indexes_directory": str(INDEXES_DIRECTORY),
                "loaded_indexes": list(INDEX_CACHE.keys()),
                "total_loaded": len(INDEX_CACHE)
            }
        
        return json.dumps(result, ensure_ascii=False, indent=2)
        
    except Exception as e:
        result = {
            "status": "error",
            "message": f"è®¾ç½®ç´¢å¼•ç›®å½•å¤±è´¥: {str(e)}"
        }
        return json.dumps(result, ensure_ascii=False, indent=2)


def main():
    """ä¸»å‡½æ•°"""
    # åˆå§‹åŒ–ç´¢å¼•ç›®å½•
    initialize_indexes_directory()
    
    # é¢„åŠ è½½ç´¢å¼•æ–‡ä»¶
    load_index_files()
    
    # è¿è¡ŒMCPæœåŠ¡å™¨
    mcp.run()


if __name__ == "__main__":
    main() 