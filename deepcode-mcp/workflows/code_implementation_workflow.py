"""
è®ºæ–‡ä»£ç å¤ç°å·¥ä½œæµ - åŸºäºMCPæ ‡å‡†çš„è¿­ä»£å¼å¼€å‘
Paper Code Implementation Workflow - MCP-compliant Iterative Development

å®ç°è®ºæ–‡ä»£ç å¤ç°çš„å®Œæ•´å·¥ä½œæµï¼š
1. æ–‡ä»¶æ ‘åˆ›å»º (File Tree Creation)
2. ä»£ç å®ç° (Code Implementation) - åŸºäºaisi-basic-agentçš„è¿­ä»£å¼å¼€å‘

ä½¿ç”¨æ ‡å‡†MCPæ¶æ„ï¼š
- MCPæœåŠ¡å™¨ï¼štools/code_implementation_server.py
- MCPå®¢æˆ·ç«¯ï¼šé€šè¿‡mcp_agentæ¡†æ¶è°ƒç”¨
- é…ç½®æ–‡ä»¶ï¼šmcp_agent.config.yaml
"""

import asyncio
import yaml
import os
from pathlib import Path
from typing import Dict, Any, Optional, List
import logging
import json
import time

# å¯¼å…¥MCPä»£ç†ç›¸å…³æ¨¡å—
from mcp_agent.agents.agent import Agent
from mcp_agent.workflows.llm.augmented_llm_anthropic import AnthropicAugmentedLLM

# å¯¼å…¥æç¤ºè¯
import sys
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from prompts.code_prompts import STRUCTURE_GENERATOR_PROMPT
from prompts.iterative_code_prompts import (
    ITERATIVE_CODE_SYSTEM_PROMPT, 
    CONTINUE_CODE_MESSAGE,
    INITIAL_ANALYSIS_PROMPT,
    COMPLETION_CHECK_PROMPT,
    ERROR_HANDLING_PROMPT,
    TOOL_USAGE_EXAMPLES
)


class CodeImplementationWorkflow:
    """
    è®ºæ–‡ä»£ç å¤ç°å·¥ä½œæµç®¡ç†å™¨
    
    ä½¿ç”¨æ ‡å‡†MCPæ¶æ„ï¼š
    1. é€šè¿‡MCPå®¢æˆ·ç«¯è¿æ¥åˆ°code-implementationæœåŠ¡å™¨
    2. ä½¿ç”¨MCPåè®®è¿›è¡Œå·¥å…·è°ƒç”¨
    3. æ”¯æŒå·¥ä½œç©ºé—´ç®¡ç†å’Œæ“ä½œå†å²è¿½è¸ª
    """
    
    def __init__(self, config_path: str = "mcp_agent.secrets.yaml"):
        self.config_path = config_path
        self.api_config = self._load_api_config()
        self.logger = self._create_logger()
        self.mcp_agent = None
    
    def _load_api_config(self) -> Dict[str, Any]:
        """åŠ è½½APIé…ç½®"""
        try:
            with open(self.config_path, 'r', encoding='utf-8') as f:
                return yaml.safe_load(f)
        except Exception as e:
            raise Exception(f"æ— æ³•åŠ è½½APIé…ç½®æ–‡ä»¶: {e}")

    def _create_logger(self) -> logging.Logger:
        """åˆ›å»ºæ—¥å¿—è®°å½•å™¨"""
        logger = logging.getLogger(__name__)
        if not logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter('%(levelname)s:%(name)s:%(message)s')
            handler.setFormatter(formatter)
            logger.addHandler(handler)
            logger.setLevel(logging.INFO)
        return logger

    def _read_plan_file(self, plan_file_path: str) -> str:
        """è¯»å–è®¡åˆ’æ–‡ä»¶"""
        plan_path = Path(plan_file_path)
        if not plan_path.exists():
            raise FileNotFoundError(f"å®ç°è®¡åˆ’æ–‡ä»¶ä¸å­˜åœ¨: {plan_file_path}")
        
        with open(plan_path, 'r', encoding='utf-8') as f:
            return f.read()

    def _check_file_tree_exists(self, target_directory: str) -> bool:
        """æ£€æŸ¥æ–‡ä»¶æ ‘æ˜¯å¦å·²å­˜åœ¨"""
        code_directory = os.path.join(target_directory, "generate_code")
        return os.path.exists(code_directory) and len(os.listdir(code_directory)) > 0

    async def _initialize_mcp_agent(self, code_directory: str):
        """åˆå§‹åŒ–MCPä»£ç†ï¼Œè¿æ¥åˆ°code-implementationæœåŠ¡å™¨"""
        try:
            # åˆ›å»ºè¿æ¥åˆ°code-implementationæœåŠ¡å™¨çš„ä»£ç†
            self.mcp_agent = Agent(
                name="CodeImplementationAgent",
                instruction="ä½ æ˜¯ä¸€ä¸ªä»£ç å®ç°åŠ©æ‰‹ï¼Œä½¿ç”¨MCPå·¥å…·æ¥å®ç°è®ºæ–‡ä»£ç å¤ç°ã€‚",
                server_names=["code-implementation"],  # è¿æ¥åˆ°æˆ‘ä»¬çš„MCPæœåŠ¡å™¨
            )
            
            # è®¾ç½®å·¥ä½œç©ºé—´
            async with self.mcp_agent:
                # åˆå§‹åŒ–LLM
                llm = await self.mcp_agent.attach_llm(AnthropicAugmentedLLM)
                
                # è®¾ç½®å·¥ä½œç©ºé—´
                workspace_result = await self.mcp_agent.call_tool(
                    "set_workspace", 
                    {"workspace_path": code_directory}
                )
                self.logger.info(f"å·¥ä½œç©ºé—´è®¾ç½®ç»“æœ: {workspace_result}")
                
                return llm
                
        except Exception as e:
            self.logger.error(f"åˆå§‹åŒ–MCPä»£ç†å¤±è´¥: {e}")
            raise

    # ==================== æ–‡ä»¶æ ‘åˆ›å»ºæµç¨‹ ====================
    
    async def create_file_structure(self, plan_content: str, target_directory: str) -> str:
        """åˆ›å»ºæ–‡ä»¶æ ‘ç»“æ„"""
        self.logger.info("å¼€å§‹åˆ›å»ºæ–‡ä»¶æ ‘ç»“æ„...")
        
        # åˆ›å»ºæ–‡ä»¶ç»“æ„ç”Ÿæˆä»£ç†
        structure_agent = Agent(
            name="StructureGeneratorAgent",
            instruction=STRUCTURE_GENERATOR_PROMPT,
            server_names=["command-executor"],
        )
        
        async with structure_agent:
            creator = await structure_agent.attach_llm(AnthropicAugmentedLLM)
            
            message = f"""åˆ†æä»¥ä¸‹å®ç°è®¡åˆ’å¹¶ç”Ÿæˆshellå‘½ä»¤æ¥åˆ›å»ºæ–‡ä»¶æ ‘ç»“æ„ã€‚

ç›®æ ‡ç›®å½•: {target_directory}/generate_code

å®ç°è®¡åˆ’:
{plan_content}

ä»»åŠ¡:
1. åœ¨å®ç°è®¡åˆ’ä¸­æ‰¾åˆ°æ–‡ä»¶æ ‘ç»“æ„
2. ç”Ÿæˆshellå‘½ä»¤ (mkdir -p, touch) æ¥åˆ›å»ºè¯¥ç»“æ„
3. ä½¿ç”¨execute_commandså·¥å…·è¿è¡Œå‘½ä»¤å¹¶åˆ›å»ºæ–‡ä»¶

è¦æ±‚:
- ä½¿ç”¨mkdir -påˆ›å»ºç›®å½•
- ä½¿ç”¨touchåˆ›å»ºæ–‡ä»¶
- ä¸ºPythonåŒ…åŒ…å«__init__.pyæ–‡ä»¶
- ä½¿ç”¨ç›¸å¯¹äºç›®æ ‡ç›®å½•çš„è·¯å¾„
- æ‰§è¡Œå‘½ä»¤ä»¥å®é™…åˆ›å»ºæ–‡ä»¶ç»“æ„"""
            
            result = await creator.generate_str(message=message)
            self.logger.info("æ–‡ä»¶æ ‘ç»“æ„åˆ›å»ºå®Œæˆ")
            return result

    # ==================== ä»£ç å®ç°æµç¨‹ ====================
    
    async def implement_code(self, plan_content: str, target_directory: str) -> str:
        """è¿­ä»£å¼ä»£ç å®ç° - ä½¿ç”¨MCPæœåŠ¡å™¨"""
        self.logger.info("å¼€å§‹è¿­ä»£å¼ä»£ç å®ç°...")
        
        code_directory = os.path.join(target_directory, "generate_code")
        if not os.path.exists(code_directory):
            raise FileNotFoundError("æ–‡ä»¶æ ‘ç»“æ„ä¸å­˜åœ¨ï¼Œè¯·å…ˆè¿è¡Œæ–‡ä»¶æ ‘åˆ›å»º")
        
        # åˆå§‹åŒ–LLMå®¢æˆ·ç«¯
        client, client_type = await self._initialize_llm_client()
        
        # åˆå§‹åŒ–MCPä»£ç†
        await self._initialize_mcp_agent(code_directory)
        
        # å‡†å¤‡å·¥å…·å®šä¹‰ (MCPæ ‡å‡†æ ¼å¼)
        tools = self._prepare_mcp_tool_definitions()
        
        # åˆå§‹åŒ–å¯¹è¯
        system_message = ITERATIVE_CODE_SYSTEM_PROMPT + "\n\n" + TOOL_USAGE_EXAMPLES
        messages = []
        
        # è·å–å½“å‰æ–‡ä»¶ç»“æ„
        file_structure = await self._get_file_structure_via_mcp()
        
        # åˆå§‹åˆ†ææ¶ˆæ¯
        initial_message = f"""å·¥ä½œç›®å½•: {code_directory}

å½“å‰æ–‡ä»¶ç»“æ„:
{file_structure}

å®ç°è®¡åˆ’:
{plan_content}

{INITIAL_ANALYSIS_PROMPT}"""
        
        messages.append({"role": "user", "content": initial_message})
        
        # è¿­ä»£å¼€å‘å¾ªç¯
        return await self._iterative_development_loop(
            client, client_type, system_message, messages, tools
        )

    async def _get_file_structure_via_mcp(self) -> str:
        """é€šè¿‡MCPè·å–æ–‡ä»¶ç»“æ„"""
        try:
            if self.mcp_agent:
                result = await self.mcp_agent.call_tool("get_file_structure", {"directory": ".", "max_depth": 5})
                return f"æ–‡ä»¶ç»“æ„:\n{result}"
            else:
                return "MCPä»£ç†æœªåˆå§‹åŒ–"
        except Exception as e:
            self.logger.error(f"è·å–æ–‡ä»¶ç»“æ„å¤±è´¥: {e}")
            return f"è·å–æ–‡ä»¶ç»“æ„å‡ºé”™: {str(e)}"

    async def _initialize_llm_client(self):
        """åˆå§‹åŒ–LLMå®¢æˆ·ç«¯"""
        # å°è¯•Anthropic API
        try:
            anthropic_key = self.api_config.get('anthropic', {}).get('api_key')
            if anthropic_key:
                from anthropic import AsyncAnthropic
                client = AsyncAnthropic(api_key=anthropic_key)
                # æµ‹è¯•è¿æ¥
                await client.messages.create(
                    model="claude-3-5-sonnet-20241022",
                    max_tokens=10,
                    messages=[{"role": "user", "content": "test"}]
                )
                self.logger.info("ä½¿ç”¨Anthropic API")
                return client, "anthropic"
        except Exception as e:
            self.logger.warning(f"Anthropic APIä¸å¯ç”¨: {e}")
        
        # å°è¯•OpenAI API
        try:
            openai_key = self.api_config.get('openai', {}).get('api_key')
            if openai_key:
                from openai import AsyncOpenAI
                client = AsyncOpenAI(api_key=openai_key)
                # æµ‹è¯•è¿æ¥
                await client.chat.completions.create(
                    model="gpt-3.5-turbo",
                    max_tokens=10,
                    messages=[{"role": "user", "content": "test"}]
                )
                self.logger.info("ä½¿ç”¨OpenAI API")
                return client, "openai"
        except Exception as e:
            self.logger.warning(f"OpenAI APIä¸å¯ç”¨: {e}")
        
        raise ValueError("æ²¡æœ‰å¯ç”¨çš„LLM API")

    async def _iterative_development_loop(self, client, client_type, system_message, messages, tools):
        """è¿­ä»£å¼€å‘å¾ªç¯ - ä½¿ç”¨MCPå·¥å…·è°ƒç”¨"""
        max_iterations = 50
        iteration = 0
        start_time = time.time()
        max_time = 3600  # 1å°æ—¶
        
        while iteration < max_iterations:
            iteration += 1
            elapsed_time = time.time() - start_time
            
            if elapsed_time > max_time:
                self.logger.warning(f"è¾¾åˆ°æ—¶é—´é™åˆ¶: {elapsed_time:.2f}s")
                break
            
            if iteration % 5 == 0:
                progress_msg = f"\n[è¿›åº¦æ›´æ–°] è¿­ä»£ {iteration}, è€—æ—¶: {elapsed_time:.2f}s / {max_time}s"
                messages.append({"role": "user", "content": progress_msg})
            
            self.logger.info(f"è¿­ä»£ {iteration}: ç”Ÿæˆå“åº”")
            
            # è°ƒç”¨LLM
            response = await self._call_llm_with_tools(
                client, client_type, system_message, messages, tools
            )
            
            messages.append({"role": "assistant", "content": response["content"]})
            
            # å¤„ç†å·¥å…·è°ƒç”¨ - ä½¿ç”¨MCP
            if response.get("tool_calls"):
                tool_results = await self._execute_mcp_tool_calls(response["tool_calls"])
                
                for tool_result in tool_results:
                    messages.append({
                        "role": "user",
                        "content": f"å·¥å…·ç»“æœ {tool_result['tool_name']}:\n{tool_result['result']}"
                    })
                
                if any("error" in result['result'] for result in tool_results):
                    messages.append({"role": "user", "content": ERROR_HANDLING_PROMPT})
            else:
                messages.append({"role": "user", "content": CONTINUE_CODE_MESSAGE})
            
            # æ£€æŸ¥å®Œæˆ
            if "implementation is complete" in response["content"].lower():
                self.logger.info("ä»£ç å®ç°å£°æ˜å®Œæˆ")
                messages.append({"role": "user", "content": COMPLETION_CHECK_PROMPT})
                final_response = await self._call_llm_with_tools(
                    client, client_type, system_message, messages, tools
                )
                if "complete" in final_response["content"].lower():
                    break
            
            # é˜²æ­¢æ¶ˆæ¯å†å²è¿‡é•¿
            if len(messages) > 100:
                messages = messages[:1] + messages[-50:]
                self.logger.info("è£å‰ªæ¶ˆæ¯å†å²")
        
        return await self._generate_final_report_via_mcp(iteration, time.time() - start_time)
    
    def _prepare_mcp_tool_definitions(self) -> List[Dict[str, Any]]:
        """
        å‡†å¤‡MCPæ ‡å‡†æ ¼å¼çš„å·¥å…·å®šä¹‰
        
        æ³¨æ„ï¼šè¿™é‡Œä½¿ç”¨MCPæ ‡å‡†çš„ inputSchema æ ¼å¼
        ç¬¦åˆå®˜æ–¹MCPè§„èŒƒï¼šhttps://modelcontextprotocol.io/docs/concepts/tools
        """
        return [
            {
                "name": "read_file",
                "description": "è¯»å–æ–‡ä»¶å†…å®¹ï¼Œæ”¯æŒæŒ‡å®šè¡Œå·èŒƒå›´",
                "inputSchema": {
                    "type": "object",
                    "properties": {
                        "file_path": {
                            "type": "string", 
                            "description": "æ–‡ä»¶è·¯å¾„ï¼Œç›¸å¯¹äºå·¥ä½œç©ºé—´"
                        },
                        "start_line": {
                            "type": "integer", 
                            "description": "èµ·å§‹è¡Œå·ï¼ˆä»1å¼€å§‹ï¼Œå¯é€‰ï¼‰"
                        },
                        "end_line": {
                            "type": "integer", 
                            "description": "ç»“æŸè¡Œå·ï¼ˆä»1å¼€å§‹ï¼Œå¯é€‰ï¼‰"
                        }
                    },
                    "required": ["file_path"]
                }
            },
            {
                "name": "write_file",
                "description": "å†™å…¥å†…å®¹åˆ°æ–‡ä»¶",
                "inputSchema": {
                    "type": "object",
                    "properties": {
                        "file_path": {
                            "type": "string", 
                            "description": "æ–‡ä»¶è·¯å¾„ï¼Œç›¸å¯¹äºå·¥ä½œç©ºé—´"
                        },
                        "content": {
                            "type": "string", 
                            "description": "è¦å†™å…¥çš„æ–‡ä»¶å†…å®¹"
                        },
                        "create_dirs": {
                            "type": "boolean", 
                            "description": "å¦‚æœç›®å½•ä¸å­˜åœ¨æ˜¯å¦åˆ›å»º",
                            "default": True
                        }
                    },
                    "required": ["file_path", "content"]
                }
            },
            {
                "name": "execute_python",
                "description": "æ‰§è¡ŒPythonä»£ç å¹¶è¿”å›è¾“å‡º",
                "inputSchema": {
                    "type": "object",
                    "properties": {
                        "code": {
                            "type": "string", 
                            "description": "è¦æ‰§è¡Œçš„Pythonä»£ç "
                        },
                        "timeout": {
                            "type": "integer", 
                            "description": "è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰",
                            "default": 30
                        }
                    },
                    "required": ["code"]
                }
            },
            {
                "name": "execute_bash",
                "description": "æ‰§è¡Œbashå‘½ä»¤",
                "inputSchema": {
                    "type": "object",
                    "properties": {
                        "command": {
                            "type": "string", 
                            "description": "è¦æ‰§è¡Œçš„bashå‘½ä»¤"
                        },
                        "timeout": {
                            "type": "integer", 
                            "description": "è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰",
                            "default": 30
                        }
                    },
                    "required": ["command"]
                }
            },
            {
                "name": "search_code",
                "description": "åœ¨ä»£ç æ–‡ä»¶ä¸­æœç´¢æ¨¡å¼",
                "inputSchema": {
                    "type": "object",
                    "properties": {
                        "pattern": {
                            "type": "string", 
                            "description": "æœç´¢æ¨¡å¼"
                        },
                        "file_pattern": {
                            "type": "string", 
                            "description": "æ–‡ä»¶æ¨¡å¼ï¼ˆå¦‚ '*.py'ï¼‰",
                            "default": "*.py"
                        },
                        "use_regex": {
                            "type": "boolean", 
                            "description": "æ˜¯å¦ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼",
                            "default": False
                        }
                    },
                    "required": ["pattern"]
                }
            },
            {
                "name": "get_file_structure",
                "description": "è·å–ç›®å½•çš„æ–‡ä»¶ç»“æ„",
                "inputSchema": {
                    "type": "object",
                    "properties": {
                        "directory": {
                            "type": "string", 
                            "description": "ç›®å½•è·¯å¾„ï¼Œç›¸å¯¹äºå·¥ä½œç©ºé—´",
                            "default": "."
                        },
                        "max_depth": {
                            "type": "integer", 
                            "description": "æœ€å¤§éå†æ·±åº¦",
                            "default": 5
                        }
                    }
                }
            }
        ]
    
    async def _call_llm_with_tools(self, client, client_type, system_message, messages, tools, max_tokens=4096):
        """è°ƒç”¨LLM"""
        try:
            if client_type == "anthropic":
                return await self._call_anthropic_with_tools(client, system_message, messages, tools, max_tokens)
            elif client_type == "openai":
                return await self._call_openai_with_tools(client, system_message, messages, tools, max_tokens)
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„å®¢æˆ·ç«¯ç±»å‹: {client_type}")
        except Exception as e:
            self.logger.error(f"LLMè°ƒç”¨å¤±è´¥: {e}")
            raise
    
    async def _call_anthropic_with_tools(self, client, system_message, messages, tools, max_tokens):
        """è°ƒç”¨Anthropic API"""
        response = await client.messages.create(
            model="claude-3-5-sonnet-20241022",
            system=system_message,
            messages=messages,
            tools=tools,
            max_tokens=max_tokens,
            temperature=0.2
        )
        
        content = ""
        tool_calls = []
        
        for block in response.content:
            if block.type == "text":
                content += block.text
            elif block.type == "tool_use":
                tool_calls.append({
                    "id": block.id,
                    "name": block.name,
                    "input": block.input
                })
        
        return {"content": content, "tool_calls": tool_calls}
    
    async def _call_openai_with_tools(self, client, system_message, messages, tools, max_tokens):
        """è°ƒç”¨OpenAI API"""
        # è½¬æ¢MCPå·¥å…·æ ¼å¼ä¸ºOpenAIæ ¼å¼
        openai_tools = []
        for tool in tools:
            openai_tools.append({
                "type": "function",
                "function": {
                    "name": tool["name"],
                    "description": tool["description"],
                    "parameters": tool["inputSchema"]
                }
            })
        
        openai_messages = [{"role": "system", "content": system_message}]
        openai_messages.extend(messages)
        
        response = await client.chat.completions.create(
            model="gpt-4-1106-preview",
            messages=openai_messages,
            tools=openai_tools if openai_tools else None,
            max_tokens=max_tokens,
            temperature=0.2
        )
        
        message = response.choices[0].message
        content = message.content or ""
        
        tool_calls = []
        if message.tool_calls:
            for tool_call in message.tool_calls:
                tool_calls.append({
                    "id": tool_call.id,
                    "name": tool_call.function.name,
                    "input": json.loads(tool_call.function.arguments)
                })
        
        return {"content": content, "tool_calls": tool_calls}
    
    async def _execute_mcp_tool_calls(self, tool_calls):
        """
        é€šè¿‡MCPåè®®æ‰§è¡Œå·¥å…·è°ƒç”¨
        
        è¿™æ˜¯æ ‡å‡†çš„MCPå®ç°æ–¹å¼ï¼Œé€šè¿‡MCPä»£ç†è°ƒç”¨æœåŠ¡å™¨å·¥å…·
        """
        results = []
        
        for tool_call in tool_calls:
            tool_name = tool_call["name"]
            tool_input = tool_call["input"]
            
            self.logger.info(f"æ‰§è¡ŒMCPå·¥å…·: {tool_name}")
            
            try:
                if self.mcp_agent:
                    # é€šè¿‡MCPåè®®è°ƒç”¨å·¥å…·
                    result = await self.mcp_agent.call_tool(tool_name, tool_input)
                    
                    results.append({
                        "tool_id": tool_call["id"],
                        "tool_name": tool_name,
                        "result": result
                    })
                else:
                    results.append({
                        "tool_id": tool_call["id"],
                        "tool_name": tool_name,
                        "result": json.dumps({
                            "status": "error",
                            "message": "MCPä»£ç†æœªåˆå§‹åŒ–"
                        }, ensure_ascii=False)
                    })
                
            except Exception as e:
                self.logger.error(f"MCPå·¥å…·æ‰§è¡Œå¤±è´¥: {e}")
                results.append({
                    "tool_id": tool_call["id"],
                    "tool_name": tool_name,
                    "result": json.dumps({
                        "status": "error",
                        "message": str(e)
                    }, ensure_ascii=False)
                })
        
        return results
    
    async def _generate_final_report_via_mcp(self, iterations: int, elapsed_time: float):
        """é€šè¿‡MCPç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š"""
        try:
            # è·å–æ“ä½œå†å²
            if self.mcp_agent:
                history_result = await self.mcp_agent.call_tool("get_operation_history", {"last_n": 20})
                history_data = json.loads(history_result) if isinstance(history_result, str) else history_result
            else:
                history_data = {"total_operations": 0, "history": []}
            
            # ç»Ÿè®¡æ“ä½œ
            operation_counts = {}
            if "history" in history_data:
                for item in history_data["history"]:
                    action = item.get("action", "unknown")
                    operation_counts[action] = operation_counts.get(action, 0) + 1
            
            report = f"""
# ä»£ç å®ç°å®ŒæˆæŠ¥å‘Š (MCPç‰ˆæœ¬)

## æ‰§è¡Œæ‘˜è¦
- æ€»è¿­ä»£æ¬¡æ•°: {iterations}
- æ€»è€—æ—¶: {elapsed_time:.2f} ç§’
- æ€»æ“ä½œæ•°: {history_data.get('total_operations', 0)}

## æ“ä½œç»Ÿè®¡
"""
            for action, count in operation_counts.items():
                report += f"- {action}: {count} æ¬¡\n"
            
            report += """
## å®æ–½æ–¹æ³•
ä½¿ç”¨äº†åŸºäºaisi-basic-agentçš„è¿­ä»£å¼å¼€å‘æ–¹æ³•ï¼š
1. åˆ†æå®ç°è®¡åˆ’å’Œæ–‡ä»¶ç»“æ„
2. è¯†åˆ«æ ¸å¿ƒç»„ä»¶å¹¶ç¡®å®šå®ç°é¡ºåº  
3. è¿­ä»£å¼å®ç°æ¯ä¸ªç»„ä»¶
4. æµ‹è¯•å’ŒéªŒè¯ä»£ç 
5. ä¿®å¤é—®é¢˜å¹¶ä¼˜åŒ–

## MCPæ¶æ„è¯´æ˜
âœ… ä½¿ç”¨æ ‡å‡†MCPå®¢æˆ·ç«¯/æœåŠ¡å™¨æ¶æ„
âœ… é€šè¿‡MCPåè®®è¿›è¡Œå·¥å…·è°ƒç”¨
âœ… æ”¯æŒå·¥ä½œç©ºé—´ç®¡ç†å’Œæ“ä½œå†å²è¿½è¸ª
âœ… å®Œå…¨ç¬¦åˆMCPè§„èŒƒ
"""
            return report
            
        except Exception as e:
            self.logger.error(f"ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Šå¤±è´¥: {e}")
            return f"ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Šå¤±è´¥: {str(e)}"

    # ==================== ä¸»å·¥ä½œæµ ====================
    
    async def run_workflow(self, plan_file_path: str, target_directory: Optional[str] = None):
        """è¿è¡Œå®Œæ•´å·¥ä½œæµ"""
        try:
            # è¯»å–å®ç°è®¡åˆ’
            plan_content = self._read_plan_file(plan_file_path)
            
            # ç¡®å®šç›®æ ‡ç›®å½•
            if target_directory is None:
                target_directory = str(Path(plan_file_path).parent)
            
            self.logger.info(f"å¼€å§‹å·¥ä½œæµ: {plan_file_path}")
            self.logger.info(f"ç›®æ ‡ç›®å½•: {target_directory}")
            
            results = {}
            
            # æ£€æŸ¥æ–‡ä»¶æ ‘æ˜¯å¦å·²å­˜åœ¨
            if self._check_file_tree_exists(target_directory):
                self.logger.info("æ–‡ä»¶æ ‘å·²å­˜åœ¨ï¼Œè·³è¿‡åˆ›å»ºæ­¥éª¤")
                results["file_tree"] = "å·²å­˜åœ¨ï¼Œè·³è¿‡åˆ›å»º"
            else:
                self.logger.info("åˆ›å»ºæ–‡ä»¶æ ‘...")
                results["file_tree"] = await self.create_file_structure(plan_content, target_directory)
            
            # ä»£ç å®ç°
            self.logger.info("å¼€å§‹ä»£ç å®ç°...")
            results["code_implementation"] = await self.implement_code(plan_content, target_directory)
            
            self.logger.info("å·¥ä½œæµæ‰§è¡ŒæˆåŠŸ")
            
            return {
                "status": "success",
                "plan_file": plan_file_path,
                "target_directory": target_directory,
                "code_directory": os.path.join(target_directory, "generate_code"),
                "results": results,
                "mcp_architecture": "standard"
            }
            
        except Exception as e:
            self.logger.error(f"å·¥ä½œæµæ‰§è¡Œå¤±è´¥: {e}")
            return {"status": "error", "message": str(e), "plan_file": plan_file_path}


# ==================== ä¸»å‡½æ•° ====================

async def main():
    """ä¸»å‡½æ•°"""
    logging.basicConfig(level=logging.INFO, format='%(levelname)s:%(name)s:%(message)s')
    
    # ç¤ºä¾‹ç”¨æ³•
    plan_file = "agent_folders/papers/1/initial_plan.txt"
    
    workflow = CodeImplementationWorkflow()
    
    # è¿è¡Œå·¥ä½œæµ
    result = await workflow.run_workflow(plan_file)
    
    # æ˜¾ç¤ºç»“æœ
    print("=" * 60)
    print("å·¥ä½œæµæ‰§è¡Œç»“æœ:")
    print(f"çŠ¶æ€: {result['status']}")
    
    if result['status'] == 'success':
        print(f"ä»£ç ç›®å½•: {result['code_directory']}")
        print(f"MCPæ¶æ„: {result.get('mcp_architecture', 'unknown')}")
        print("æ‰§è¡Œå®Œæˆ!")
    else:
        print(f"é”™è¯¯ä¿¡æ¯: {result['message']}")
    
    print("=" * 60)
    print("\nâœ… ä½¿ç”¨æ ‡å‡†MCPæ¶æ„")
    print("ğŸ”§ MCPæœåŠ¡å™¨: tools/code_implementation_server.py")
    print("ğŸ“‹ é…ç½®æ–‡ä»¶: mcp_agent.config.yaml")


if __name__ == "__main__":
    asyncio.run(main())
