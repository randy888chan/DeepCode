"""
Streamlit äº‹ä»¶å¤„ç†æ¨¡å— / Streamlit Event Handlers Module

åŒ…å«æ‰€æœ‰äº‹ä»¶å¤„ç†å’Œä¸šåŠ¡é€»è¾‘
Contains all event handling and business logic
"""

import asyncio
import time
import os
import sys
import traceback
import tempfile
import atexit
import signal
from datetime import datetime
from typing import Dict, Any, Optional

import streamlit as st
import nest_asyncio
import concurrent.futures

# å¯¼å…¥å¿…è¦çš„æ¨¡å—
from mcp_agent.app import MCPApp
from workflows.initial_workflows import (
    execute_multi_agent_research_pipeline,
    run_paper_analyzer,
    run_paper_downloader
)


def _emergency_cleanup():
    """
    åº”æ€¥èµ„æºæ¸…ç†å‡½æ•° / Emergency resource cleanup function
    åœ¨ç¨‹åºå¼‚å¸¸é€€å‡ºæ—¶è°ƒç”¨ / Called when program exits abnormally
    """
    try:
        cleanup_resources()
    except Exception:
        pass  # é™é»˜å¤„ç†ï¼Œé¿å…åœ¨é€€å‡ºæ—¶æŠ›å‡ºæ–°å¼‚å¸¸


def _signal_handler(signum, frame):
    """
    ä¿¡å·å¤„ç†å™¨ / Signal handler
    å¤„ç†ç¨‹åºç»ˆæ­¢ä¿¡å· / Handle program termination signals
    """
    try:
        cleanup_resources()
    except Exception:
        pass
    finally:
        # æ¢å¤é»˜è®¤ä¿¡å·å¤„ç†å¹¶é‡æ–°å‘é€ä¿¡å·
        signal.signal(signum, signal.SIG_DFL)
        os.kill(os.getpid(), signum)


# æ³¨å†Œé€€å‡ºæ¸…ç†å‡½æ•° / Register exit cleanup function
atexit.register(_emergency_cleanup)

# æ³¨å†Œä¿¡å·å¤„ç†å™¨ / Register signal handlers
# åœ¨æŸäº›ç¯å¢ƒä¸­ï¼ˆå¦‚ Streamlitï¼‰ï¼Œä¿¡å·å¤„ç†å¯èƒ½å—é™ï¼Œéœ€è¦æ›´åŠ å°å¿ƒ
def _safe_register_signal_handlers():
    """å®‰å…¨åœ°æ³¨å†Œä¿¡å·å¤„ç†å™¨ / Safely register signal handlers"""
    try:
        # æ£€æŸ¥æ˜¯å¦åœ¨ä¸»çº¿ç¨‹ä¸­
        import threading
        if threading.current_thread() is not threading.main_thread():
            return  # ä¿¡å·å¤„ç†å™¨åªèƒ½åœ¨ä¸»çº¿ç¨‹ä¸­æ³¨å†Œ
        
        # å°è¯•æ³¨å†Œä¿¡å·å¤„ç†å™¨
        signal.signal(signal.SIGTERM, _signal_handler)
        signal.signal(signal.SIGINT, _signal_handler)
        if hasattr(signal, 'SIGBREAK'):  # Windows
            signal.signal(signal.SIGBREAK, _signal_handler)
    except (AttributeError, OSError, ValueError) as e:
        # æŸäº›ä¿¡å·åœ¨æŸäº›å¹³å°ä¸Šä¸å¯ç”¨ï¼Œæˆ–è€…åœ¨æŸäº›è¿è¡Œç¯å¢ƒä¸­è¢«ç¦ç”¨
        # è¿™åœ¨ Streamlit ç­‰ Web æ¡†æ¶ä¸­å¾ˆå¸¸è§
        pass

# å»¶è¿Ÿæ³¨å†Œä¿¡å·å¤„ç†å™¨ï¼Œé¿å…åœ¨æ¨¡å—å¯¼å…¥æ—¶å‡ºé”™
try:
    _safe_register_signal_handlers()
except Exception:
    # å¦‚æœæ³¨å†Œå¤±è´¥ï¼Œé™é»˜å¿½ç•¥ï¼Œä¸å½±å“åº”ç”¨å¯åŠ¨
    pass


async def process_input_async(input_source: str, input_type: str, enable_indexing: bool = True, progress_callback=None) -> Dict[str, Any]:
    """
    å¼‚æ­¥å¤„ç†è¾“å…¥ / Process input asynchronously
    
    Args:
        input_source: è¾“å…¥æº / Input source
        input_type: è¾“å…¥ç±»å‹ / Input type
        enable_indexing: æ˜¯å¦å¯ç”¨ç´¢å¼•åŠŸèƒ½ / Whether to enable indexing
        progress_callback: è¿›åº¦å›è°ƒå‡½æ•° / Progress callback function
        
    Returns:
        å¤„ç†ç»“æœ / Processing result
    """
    try:
        # åœ¨åŒä¸€ä¸ªå¼‚æ­¥ä¸Šä¸‹æ–‡ä¸­åˆ›å»ºå’Œä½¿ç”¨ MCP åº”ç”¨
        app = MCPApp(name="paper_to_code")
        
        async with app.run() as agent_app:
            logger = agent_app.logger
            context = agent_app.context
            context.config.mcp.servers["filesystem"].args.extend([os.getcwd()])
            
            # åˆå§‹åŒ–è¿›åº¦ / Initialize Progress
            if progress_callback:
                progress_callback(5, "ğŸš€ Initializing AI research engine...")
            
            # è°ƒç”¨å®Œæ•´çš„å¤šæ™ºèƒ½ä½“ç ”ç©¶æµæ°´çº¿ / Call complete multi-agent research pipeline
            # ç°åœ¨execute_multi_agent_research_pipelineåŒ…å«äº†æ‰€æœ‰æ­¥éª¤ï¼šåˆ†æã€ä¸‹è½½ã€ä»£ç å‡†å¤‡å’Œå®ç°
            repo_result = await execute_multi_agent_research_pipeline(
                input_source, 
                logger, 
                progress_callback,
                enable_indexing=enable_indexing  # ä¼ é€’ç´¢å¼•æ§åˆ¶å‚æ•°
            )
            
            return {
                "analysis_result": "Integrated into complete workflow",
                "download_result": "Integrated into complete workflow", 
                "repo_result": repo_result,
                "status": "success"
            }
            
    except Exception as e:
        error_msg = str(e)
        traceback_msg = traceback.format_exc()
        
        return {
            "error": error_msg,
            "traceback": traceback_msg,
            "status": "error"
        }


def run_async_task(coro):
    """
    è¿è¡Œå¼‚æ­¥ä»»åŠ¡çš„è¾…åŠ©å‡½æ•° / Helper function to run async tasks
    
    Args:
        coro: åç¨‹å¯¹è±¡ / Coroutine object
        
    Returns:
        ä»»åŠ¡ç»“æœ / Task result
    """
    # åº”ç”¨ nest_asyncio æ¥æ”¯æŒåµŒå¥—çš„äº‹ä»¶å¾ªç¯
    nest_asyncio.apply()
    
    # ä¿å­˜å½“å‰çš„ Streamlit ä¸Šä¸‹æ–‡
    try:
        from streamlit.runtime.scriptrunner import get_script_run_ctx
        from streamlit.runtime.scriptrunner.script_run_context import SCRIPT_RUN_CONTEXT_ATTR_NAME
        import threading
        
        current_ctx = get_script_run_ctx()
        context_available = True
    except ImportError:
        # å¦‚æœæ— æ³•å¯¼å…¥ Streamlit ä¸Šä¸‹æ–‡ç›¸å…³æ¨¡å—ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ³•
        current_ctx = None
        context_available = False
    
    def run_in_new_loop():
        """åœ¨æ–°çš„äº‹ä»¶å¾ªç¯ä¸­è¿è¡Œåç¨‹ / Run coroutine in new event loop"""
        # åœ¨æ–°çº¿ç¨‹ä¸­è®¾ç½® Streamlit ä¸Šä¸‹æ–‡ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if context_available and current_ctx:
            try:
                import threading
                setattr(threading.current_thread(), SCRIPT_RUN_CONTEXT_ATTR_NAME, current_ctx)
            except Exception:
                pass  # å¿½ç•¥ä¸Šä¸‹æ–‡è®¾ç½®é”™è¯¯
        
        loop = None
        try:
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            result = loop.run_until_complete(coro)
            return result
        except Exception as e:
            raise e
        finally:
            # æ¸…ç†èµ„æº
            if loop:
                try:
                    loop.close()
                except Exception:
                    pass
            asyncio.set_event_loop(None)
            
            # æ¸…ç†çº¿ç¨‹ä¸Šä¸‹æ–‡ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if context_available:
                try:
                    import threading
                    if hasattr(threading.current_thread(), SCRIPT_RUN_CONTEXT_ATTR_NAME):
                        delattr(threading.current_thread(), SCRIPT_RUN_CONTEXT_ATTR_NAME)
                except Exception:
                    pass  # å¿½ç•¥æ¸…ç†é”™è¯¯
            
            # å¼ºåˆ¶åƒåœ¾å›æ”¶
            import gc
            gc.collect()
    
    # ä½¿ç”¨çº¿ç¨‹æ± æ¥è¿è¡Œå¼‚æ­¥ä»»åŠ¡ï¼Œé¿å…äº‹ä»¶å¾ªç¯å†²çª
    executor = None
    try:
        executor = concurrent.futures.ThreadPoolExecutor(
            max_workers=1,
                            thread_name_prefix="deepcode_ctx_async"
        )
        future = executor.submit(run_in_new_loop)
        result = future.result(timeout=300)  # 5åˆ†é’Ÿè¶…æ—¶
        return result
    except concurrent.futures.TimeoutError:
        st.error("Processing timeout after 5 minutes. Please try again.")
        raise TimeoutError("Processing timeout")
    except Exception as e:
        # å¦‚æœçº¿ç¨‹æ± æ‰§è¡Œå¤±è´¥ï¼Œå°è¯•ç›´æ¥è¿è¡Œ
        st.warning(f"Threaded async execution failed: {e}, trying direct execution...")
        try:
            # å¤‡ç”¨æ–¹æ³•ï¼šç›´æ¥åœ¨å½“å‰çº¿ç¨‹ä¸­è¿è¡Œ
            loop = None
            try:
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                result = loop.run_until_complete(coro)
                return result
            finally:
                if loop:
                    try:
                        loop.close()
                    except Exception:
                        pass
                asyncio.set_event_loop(None)
                import gc
                gc.collect()
        except Exception as backup_error:
            st.error(f"All execution methods failed: {backup_error}")
            raise backup_error
    finally:
        # ç¡®ä¿çº¿ç¨‹æ± è¢«æ­£ç¡®å…³é—­
        if executor:
            try:
                executor.shutdown(wait=True, cancel_futures=True)
            except Exception:
                pass
        # å¼ºåˆ¶åƒåœ¾å›æ”¶
        import gc
        gc.collect()


def run_async_task_simple(coro):
    """
    ç®€å•çš„å¼‚æ­¥ä»»åŠ¡è¿è¡Œå™¨ï¼Œé¿å…å¤šçº¿ç¨‹é—®é¢˜ / Simple async task runner avoiding threading issues
    
    Args:
        coro: åç¨‹å¯¹è±¡ / Coroutine object
        
    Returns:
        ä»»åŠ¡ç»“æœ / Task result
    """
    # åº”ç”¨ nest_asyncio æ¥æ”¯æŒåµŒå¥—çš„äº‹ä»¶å¾ªç¯
    nest_asyncio.apply()
    
    try:
        # å°è¯•åœ¨å½“å‰äº‹ä»¶å¾ªç¯ä¸­è¿è¡Œ
        loop = asyncio.get_event_loop()
        if loop.is_running():
            # å¦‚æœå½“å‰å¾ªç¯æ­£åœ¨è¿è¡Œï¼Œä½¿ç”¨æ”¹è¿›çš„çº¿ç¨‹æ± æ–¹æ³•
            import concurrent.futures
            import threading
            import gc
            
            def run_in_thread():
                # åˆ›å»ºæ–°çš„äº‹ä»¶å¾ªç¯å¹¶è®¾ç½®ä¸ºå½“å‰çº¿ç¨‹çš„å¾ªç¯
                new_loop = asyncio.new_event_loop()
                asyncio.set_event_loop(new_loop)
                try:
                    result = new_loop.run_until_complete(coro)
                    return result
                except Exception as e:
                    # ç¡®ä¿å¼‚å¸¸ä¿¡æ¯è¢«æ­£ç¡®ä¼ é€’
                    raise e
                finally:
                    # ç¡®ä¿å¾ªç¯è¢«æ­£ç¡®å…³é—­
                    try:
                        new_loop.close()
                    except Exception:
                        pass
                    # æ¸…é™¤å½“å‰çº¿ç¨‹çš„äº‹ä»¶å¾ªç¯å¼•ç”¨
                    asyncio.set_event_loop(None)
                    # å¼ºåˆ¶åƒåœ¾å›æ”¶
                    gc.collect()
            
            # ä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨ç¡®ä¿çº¿ç¨‹æ± è¢«æ­£ç¡®å…³é—­
            executor = None
            try:
                executor = concurrent.futures.ThreadPoolExecutor(
                    max_workers=1,
                    thread_name_prefix="deepcode_async"
                )
                future = executor.submit(run_in_thread)
                result = future.result(timeout=300)  # 5åˆ†é’Ÿè¶…æ—¶
                return result
            except concurrent.futures.TimeoutError:
                st.error("Processing timeout after 5 minutes. Please try again with a smaller file.")
                raise TimeoutError("Processing timeout")
            except Exception as e:
                st.error(f"Async processing error: {e}")
                raise e
            finally:
                # ç¡®ä¿çº¿ç¨‹æ± è¢«æ­£ç¡®å…³é—­
                if executor:
                    try:
                        executor.shutdown(wait=True, cancel_futures=True)
                    except Exception:
                        pass
                # å¼ºåˆ¶åƒåœ¾å›æ”¶
                gc.collect()
        else:
            # ç›´æ¥åœ¨å½“å‰å¾ªç¯ä¸­è¿è¡Œ
            return loop.run_until_complete(coro)
    except Exception as e:
        # æœ€åçš„å¤‡ç”¨æ–¹æ³•ï¼šåˆ›å»ºæ–°çš„äº‹ä»¶å¾ªç¯
        loop = None
        try:
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            result = loop.run_until_complete(coro)
            return result
        except Exception as backup_error:
            st.error(f"All async methods failed: {backup_error}")
            raise backup_error
        finally:
            if loop:
                try:
                    loop.close()
                except Exception:
                    pass
            asyncio.set_event_loop(None)
            # å¼ºåˆ¶åƒåœ¾å›æ”¶
            import gc
            gc.collect()


def handle_processing_workflow(input_source: str, input_type: str, enable_indexing: bool = True) -> Dict[str, Any]:
    """
    å¤„ç†å·¥ä½œæµçš„ä¸»è¦å¤„ç†å‡½æ•° / Main processing function for workflow
    
    Args:
        input_source: è¾“å…¥æº / Input source
        input_type: è¾“å…¥ç±»å‹ / Input type
        enable_indexing: æ˜¯å¦å¯ç”¨ç´¢å¼•åŠŸèƒ½ / Whether to enable indexing
        
    Returns:
        å¤„ç†ç»“æœ / Processing result
    """
    from .components import enhanced_progress_display_component, update_step_indicator, display_status
    
    # æ˜¾ç¤ºå¢å¼ºç‰ˆè¿›åº¦ç»„ä»¶
    progress_bar, status_text, step_indicators, workflow_steps = enhanced_progress_display_component(enable_indexing)
    
    # æ­¥éª¤æ˜ å°„ï¼šå°†è¿›åº¦ç™¾åˆ†æ¯”æ˜ å°„åˆ°æ­¥éª¤ç´¢å¼• - æ ¹æ®ç´¢å¼•å¼€å…³è°ƒæ•´
    if not enable_indexing:
        # è·³è¿‡ç´¢å¼•ç›¸å…³æ­¥éª¤çš„è¿›åº¦æ˜ å°„ - å¿«é€Ÿæ¨¡å¼é¡ºåºï¼šInitialize -> Analyze -> Download -> Plan -> Implement
        step_mapping = {
            5: 0,   # Initialize
            10: 1,  # Analyze
            25: 2,  # Download
            40: 3,  # Plan (ç°åœ¨ä¼˜å…ˆäºReferencesï¼Œ40%)
            85: 4,  # Implement (è·³è¿‡ References, Repos å’Œ Index)
            100: 4  # Complete
        }
    else:
        # å®Œæ•´å·¥ä½œæµçš„æ­¥éª¤æ˜ å°„ - æ–°é¡ºåºï¼šInitialize -> Analyze -> Download -> Plan -> References -> Repos -> Index -> Implement
        step_mapping = {
            5: 0,   # Initialize
            10: 1,  # Analyze
            25: 2,  # Download
            40: 3,  # Plan (ç°åœ¨åœ¨ç¬¬4ä½ï¼Œ40%)
            50: 4,  # References (ç°åœ¨åœ¨ç¬¬5ä½ï¼Œæ¡ä»¶æ€§ï¼Œ50%)
            60: 5,  # Repos (GitHubä¸‹è½½)
            70: 6,  # Index (ä»£ç ç´¢å¼•)
            85: 7,  # Implement (ä»£ç å®ç°)
            100: 7  # Complete
        }
    
    current_step = 0
    
    # å®šä¹‰å¢å¼ºç‰ˆè¿›åº¦å›è°ƒå‡½æ•° / Define enhanced progress callback function
    def update_progress(progress: int, message: str):
        nonlocal current_step
        
        # æ›´æ–°è¿›åº¦æ¡
        progress_bar.progress(progress)
        status_text.markdown(f"**{message}**")
        
        # ç¡®å®šå½“å‰æ­¥éª¤
        new_step = step_mapping.get(progress, current_step)
        if new_step != current_step:
            current_step = new_step
            update_step_indicator(step_indicators, workflow_steps, current_step, "active")
        
        time.sleep(0.3)  # çŸ­æš‚åœé¡¿ä»¥ä¾¿ç”¨æˆ·çœ‹åˆ°è¿›åº¦å˜åŒ–
    
    # æ­¥éª¤1: åˆå§‹åŒ– / Step 1: Initialization
    if enable_indexing:
        update_progress(5, "ğŸš€ Initializing AI research engine and loading models...")
    else:
        update_progress(5, "ğŸš€ Initializing AI research engine (Fast mode - indexing disabled)...")
    update_step_indicator(step_indicators, workflow_steps, 0, "active")
    
    # å¼€å§‹å¼‚æ­¥å¤„ç†ï¼Œä½¿ç”¨è¿›åº¦å›è°ƒ
    with st.spinner("ğŸ”„ Processing workflow stages..."):
        try:
            # é¦–å…ˆå°è¯•ä½¿ç”¨ç®€å•çš„å¼‚æ­¥å¤„ç†æ–¹æ³•
            result = run_async_task_simple(process_input_async(input_source, input_type, enable_indexing, update_progress))
        except Exception as e:
            st.warning(f"Primary async method failed: {e}")
            # å¤‡ç”¨æ–¹æ³•ï¼šä½¿ç”¨åŸå§‹çš„çº¿ç¨‹æ± æ–¹æ³•
            try:
                result = run_async_task(process_input_async(input_source, input_type, enable_indexing, update_progress))
            except Exception as backup_error:
                st.error(f"Both async methods failed. Error: {backup_error}")
                return {
                    "status": "error",
                    "error": str(backup_error),
                    "traceback": traceback.format_exc()
                }
    
    # æ ¹æ®ç»“æœæ›´æ–°æœ€ç»ˆçŠ¶æ€
    if result["status"] == "success":
        # å®Œæˆæ‰€æœ‰æ­¥éª¤
        update_progress(100, "âœ… All processing stages completed successfully!")
        update_step_indicator(step_indicators, workflow_steps, len(workflow_steps), "completed")
        
        # æ˜¾ç¤ºæˆåŠŸä¿¡æ¯
        st.balloons()  # æ·»åŠ åº†ç¥åŠ¨ç”»
        if enable_indexing:
            display_status("ğŸ‰ Workflow completed! Your research paper has been successfully processed and code has been generated.", "success")
        else:
            display_status("ğŸ‰ Fast workflow completed! Your research paper has been processed (indexing skipped for faster processing).", "success")
        
    else:
        # å¤„ç†å¤±è´¥
        update_progress(0, "âŒ Processing failed - see error details below")
        update_step_indicator(step_indicators, workflow_steps, current_step, "error")
        display_status(f"âŒ Processing encountered an error: {result.get('error', 'Unknown error')}", "error")
    
    # ç­‰å¾…ä¸€ä¸‹è®©ç”¨æˆ·çœ‹åˆ°å®ŒæˆçŠ¶æ€
    time.sleep(2.5)
    
    return result


def update_session_state_with_result(result: Dict[str, Any], input_type: str):
    """
    ç”¨ç»“æœæ›´æ–°session state / Update session state with result
    
    Args:
        result: å¤„ç†ç»“æœ / Processing result
        input_type: è¾“å…¥ç±»å‹ / Input type
    """
    if result["status"] == "success":
        # ä¿å­˜ç»“æœåˆ°session state
        st.session_state.last_result = result
        st.session_state.show_results = True
        
        # ä¿å­˜åˆ°å†å²è®°å½•
        st.session_state.results.append({
            "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "input_type": input_type,
            "status": "success",
            "result": result
        })
    else:
        # ä¿å­˜é”™è¯¯ä¿¡æ¯åˆ°session stateç”¨äºæ˜¾ç¤º
        st.session_state.last_error = result.get("error", "Unknown error")
        
        # ä¿å­˜é”™è¯¯åˆ°å†å²è®°å½•
        st.session_state.results.append({
            "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "input_type": input_type,
            "status": "error",
            "error": result.get("error", "Unknown error")
        })
    
    # é™åˆ¶å†å²è®°å½•æœ€å¤šä¿å­˜50æ¡
    if len(st.session_state.results) > 50:
        st.session_state.results = st.session_state.results[-50:]


def cleanup_temp_file(input_source: str, input_type: str):
    """
    æ¸…ç†ä¸´æ—¶æ–‡ä»¶ / Cleanup temporary file
    
    Args:
        input_source: è¾“å…¥æº / Input source
        input_type: è¾“å…¥ç±»å‹ / Input type
    """
    if input_type == "file" and input_source and os.path.exists(input_source):
        try:
            os.unlink(input_source)
        except:
            pass


def handle_start_processing_button(input_source: str, input_type: str):
    """
    å¤„ç†å¼€å§‹å¤„ç†æŒ‰é’®ç‚¹å‡» / Handle start processing button click
    
    Args:
        input_source: è¾“å…¥æº / Input source
        input_type: è¾“å…¥ç±»å‹ / Input type
    """
    from .components import display_status
    
    st.session_state.processing = True
    
    # è·å–ç´¢å¼•å¼€å…³çŠ¶æ€
    enable_indexing = st.session_state.get("enable_indexing", True)
    
    try:
        # å¤„ç†å·¥ä½œæµ
        result = handle_processing_workflow(input_source, input_type, enable_indexing)
        
        # æ˜¾ç¤ºç»“æœçŠ¶æ€
        if result["status"] == "success":
            display_status("All operations completed successfully! ğŸ‰", "success")
        else:
            display_status(f"Error during processing", "error")
        
        # æ›´æ–°session state
        update_session_state_with_result(result, input_type)
        
    except Exception as e:
        # å¤„ç†å¼‚å¸¸æƒ…å†µ
        st.error(f"Unexpected error during processing: {e}")
        result = {"status": "error", "error": str(e)}
        update_session_state_with_result(result, input_type)
    
    finally:
        # å¤„ç†å®Œæˆåé‡ç½®çŠ¶æ€å’Œæ¸…ç†èµ„æº
        st.session_state.processing = False
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        cleanup_temp_file(input_source, input_type)
        
        # æ¸…ç†ç³»ç»Ÿèµ„æº
        cleanup_resources()
        
        # é‡æ–°è¿è¡Œä»¥æ˜¾ç¤ºç»“æœæˆ–é”™è¯¯
        st.rerun()


def handle_error_display():
    """
    å¤„ç†é”™è¯¯æ˜¾ç¤º / Handle error display
    """
    if hasattr(st.session_state, 'last_error') and st.session_state.last_error:
        st.error(f"âŒ Error: {st.session_state.last_error}")
        if st.button("ğŸ”„ Try Again", type="secondary", use_container_width=True):
            st.session_state.last_error = None
            st.session_state.task_counter += 1
            st.rerun()


def initialize_session_state():
    """
    åˆå§‹åŒ–session state / Initialize session state
    """
    if 'processing' not in st.session_state:
        st.session_state.processing = False
    if 'results' not in st.session_state:
        st.session_state.results = []
    if 'current_step' not in st.session_state:
        st.session_state.current_step = 0
    if 'task_counter' not in st.session_state:
        st.session_state.task_counter = 0
    if 'show_results' not in st.session_state:
        st.session_state.show_results = False
    if 'last_result' not in st.session_state:
        st.session_state.last_result = None
    if 'last_error' not in st.session_state:
        st.session_state.last_error = None
    if 'enable_indexing' not in st.session_state:
        st.session_state.enable_indexing = True  # é»˜è®¤å¯ç”¨ç´¢å¼•åŠŸèƒ½ 


def cleanup_resources():
    """
    æ¸…ç†ç³»ç»Ÿèµ„æºï¼Œé˜²æ­¢å†…å­˜æ³„éœ² / Clean up system resources to prevent memory leaks
    """
    try:
        import gc
        import threading
        import multiprocessing
        import asyncio
        import sys
        
        # 1. æ¸…ç†asyncioç›¸å…³èµ„æº
        try:
            # è·å–å½“å‰äº‹ä»¶å¾ªç¯ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            try:
                loop = asyncio.get_running_loop()
                # å–æ¶ˆæ‰€æœ‰æŒ‚èµ·çš„ä»»åŠ¡
                if loop and not loop.is_closed():
                    pending_tasks = [task for task in asyncio.all_tasks(loop) if not task.done()]
                    if pending_tasks:
                        for task in pending_tasks:
                            if not task.cancelled():
                                task.cancel()
                        # ç­‰å¾…ä»»åŠ¡å–æ¶ˆå®Œæˆ
                        try:
                            if pending_tasks:
                                # ä½¿ç”¨è¶…æ—¶é¿å…é˜»å¡å¤ªä¹…
                                import time
                                time.sleep(0.1)
                        except Exception:
                            pass
            except RuntimeError:
                # æ²¡æœ‰è¿è¡Œä¸­çš„äº‹ä»¶å¾ªç¯ï¼Œç»§ç»­å…¶ä»–æ¸…ç†
                pass
        except Exception:
            pass
        
        # 2. å¼ºåˆ¶åƒåœ¾å›æ”¶
        gc.collect()
        
        # 3. æ¸…ç†æ´»è·ƒçº¿ç¨‹ï¼ˆé™¤ä¸»çº¿ç¨‹å¤–ï¼‰
        active_threads = threading.active_count()
        if active_threads > 1:
            # ç­‰å¾…ä¸€æ®µæ—¶é—´è®©çº¿ç¨‹è‡ªç„¶ç»“æŸ
            import time
            time.sleep(0.5)
        
        # 4. æ¸…ç†multiprocessingèµ„æº
        try:
            # æ¸…ç†å¯èƒ½çš„å¤šè¿›ç¨‹èµ„æº
            if hasattr(multiprocessing, 'active_children'):
                for child in multiprocessing.active_children():
                    if child.is_alive():
                        child.terminate()
                        child.join(timeout=1.0)
                        # å¦‚æœjoinè¶…æ—¶ï¼Œå¼ºåˆ¶kill
                        if child.is_alive():
                            try:
                                child.kill()
                                child.join(timeout=0.5)
                            except Exception:
                                pass
            
            # æ¸…ç†multiprocessingç›¸å…³çš„èµ„æºè¿½è¸ªå™¨
            try:
                import multiprocessing.resource_tracker
                if hasattr(multiprocessing.resource_tracker, '_resource_tracker'):
                    tracker = multiprocessing.resource_tracker._resource_tracker
                    if tracker and hasattr(tracker, '_stop'):
                        tracker._stop()
            except Exception:
                pass
                
        except Exception:
            pass
        
        # 5. å¼ºåˆ¶æ¸…ç†Pythonå†…éƒ¨ç¼“å­˜
        try:
            # æ¸…ç†æ¨¡å—ç¼“å­˜ä¸­çš„ä¸€äº›ä¸´æ—¶å¯¹è±¡
            import sys
            # ä¸åˆ é™¤å…³é”®æ¨¡å—ï¼Œåªæ¸…ç†å¯èƒ½çš„ä¸´æ—¶èµ„æº
            if hasattr(sys, '_clear_type_cache'):
                sys._clear_type_cache()
        except Exception:
            pass
        
        # 6. æœ€ç»ˆåƒåœ¾å›æ”¶
        gc.collect()
            
    except Exception as e:
        # é™é»˜å¤„ç†æ¸…ç†é”™è¯¯ï¼Œé¿å…å½±å“ä¸»æµç¨‹
        # ä½†åœ¨è°ƒè¯•æ¨¡å¼ä¸‹å¯ä»¥è®°å½•é”™è¯¯
        try:
            import logging
            logging.getLogger(__name__).debug(f"Resource cleanup warning: {e}")
        except Exception:
            pass 