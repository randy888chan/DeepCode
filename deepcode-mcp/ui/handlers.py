"""
Streamlit äº‹ä»¶å¤„ç†æ¨¡å— / Streamlit Event Handlers Module

åŒ…å«æ‰€æœ‰äº‹ä»¶å¤„ç†å’Œä¸šåŠ¡é€»è¾‘
Contains all event handling and business logic
"""

import asyncio
import time
import os
import sys
import traceback
import tempfile
from datetime import datetime
from typing import Dict, Any, Optional

import streamlit as st
import nest_asyncio
import concurrent.futures
import uuid

# å¯¼å…¥å¿…è¦çš„æ¨¡å—
from mcp_agent.app import MCPApp
from workflows.initial_workflows import (
    execute_multi_agent_research_pipeline,
    run_paper_analyzer,
    run_paper_downloader
)


async def process_input_async(input_source: str, input_type: str, progress_callback=None) -> Dict[str, Any]:
    """
    å¼‚æ­¥å¤„ç†è¾“å…¥ / Process input asynchronously
    
    Args:
        input_source: è¾“å…¥æº / Input source
        input_type: è¾“å…¥ç±»å‹ / Input type
        progress_callback: è¿›åº¦å›è°ƒå‡½æ•° / Progress callback function
        
    Returns:
        å¤„ç†ç»“æœ / Processing result
    """
    try:
        # åœ¨åŒä¸€ä¸ªå¼‚æ­¥ä¸Šä¸‹æ–‡ä¸­åˆ›å»ºå’Œä½¿ç”¨ MCP åº”ç”¨
        app = MCPApp(name="paper_to_code")
        
        async with app.run() as agent_app:
            logger = agent_app.logger
            context = agent_app.context
            context.config.mcp.servers["filesystem"].args.extend([os.getcwd()])
            
            # åˆå§‹åŒ–è¿›åº¦ / Initialize Progress
            if progress_callback:
                progress_callback(5, "ğŸš€ Initializing AI research engine...")
            
            # è°ƒç”¨å®Œæ•´çš„å¤šæ™ºèƒ½ä½“ç ”ç©¶æµæ°´çº¿ / Call complete multi-agent research pipeline
            # ç°åœ¨execute_multi_agent_research_pipelineåŒ…å«äº†æ‰€æœ‰æ­¥éª¤ï¼šåˆ†æã€ä¸‹è½½ã€ä»£ç å‡†å¤‡å’Œå®ç°
            repo_result = await execute_multi_agent_research_pipeline(input_source, logger, progress_callback)
            
            return {
                "analysis_result": "Integrated into complete workflow",
                "download_result": "Integrated into complete workflow", 
                "repo_result": repo_result,
                "status": "success"
            }
            
    except Exception as e:
        error_msg = str(e)
        traceback_msg = traceback.format_exc()
        
        return {
            "error": error_msg,
            "traceback": traceback_msg,
            "status": "error"
        }


def run_async_task(coro):
    """
    è¿è¡Œå¼‚æ­¥ä»»åŠ¡çš„è¾…åŠ©å‡½æ•° / Helper function to run async tasks
    
    Args:
        coro: åç¨‹å¯¹è±¡ / Coroutine object
        
    Returns:
        ä»»åŠ¡ç»“æœ / Task result
    """
    # åº”ç”¨ nest_asyncio æ¥æ”¯æŒåµŒå¥—çš„äº‹ä»¶å¾ªç¯
    nest_asyncio.apply()
    
    # ä¿å­˜å½“å‰çš„ Streamlit ä¸Šä¸‹æ–‡
    try:
        from streamlit.runtime.scriptrunner import get_script_run_ctx
        from streamlit.runtime.scriptrunner.script_run_context import SCRIPT_RUN_CONTEXT_ATTR_NAME
        import threading
        
        current_ctx = get_script_run_ctx()
        context_available = True
    except ImportError:
        # å¦‚æœæ— æ³•å¯¼å…¥ Streamlit ä¸Šä¸‹æ–‡ç›¸å…³æ¨¡å—ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ³•
        current_ctx = None
        context_available = False
    
    def run_in_new_loop():
        """åœ¨æ–°çš„äº‹ä»¶å¾ªç¯ä¸­è¿è¡Œåç¨‹ / Run coroutine in new event loop"""
        # åœ¨æ–°çº¿ç¨‹ä¸­è®¾ç½® Streamlit ä¸Šä¸‹æ–‡ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if context_available and current_ctx:
            try:
                import threading
                setattr(threading.current_thread(), SCRIPT_RUN_CONTEXT_ATTR_NAME, current_ctx)
            except Exception:
                pass  # å¿½ç•¥ä¸Šä¸‹æ–‡è®¾ç½®é”™è¯¯
        
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        try:
            return loop.run_until_complete(coro)
        finally:
            loop.close()
            asyncio.set_event_loop(None)
            # æ¸…ç†çº¿ç¨‹ä¸Šä¸‹æ–‡ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if context_available:
                try:
                    import threading
                    if hasattr(threading.current_thread(), SCRIPT_RUN_CONTEXT_ATTR_NAME):
                        delattr(threading.current_thread(), SCRIPT_RUN_CONTEXT_ATTR_NAME)
                except Exception:
                    pass  # å¿½ç•¥æ¸…ç†é”™è¯¯
    
    # ä½¿ç”¨çº¿ç¨‹æ± æ¥è¿è¡Œå¼‚æ­¥ä»»åŠ¡ï¼Œé¿å…äº‹ä»¶å¾ªç¯å†²çª
    try:
        with concurrent.futures.ThreadPoolExecutor(max_workers=1) as executor:
            future = executor.submit(run_in_new_loop)
            return future.result()
    except Exception as e:
        # å¦‚æœçº¿ç¨‹æ± æ‰§è¡Œå¤±è´¥ï¼Œå°è¯•ç›´æ¥è¿è¡Œ
        st.error(f"Async task execution error: {e}")
        try:
            # å¤‡ç”¨æ–¹æ³•ï¼šç›´æ¥åœ¨å½“å‰çº¿ç¨‹ä¸­è¿è¡Œ
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            try:
                result = loop.run_until_complete(coro)
                return result
            finally:
                loop.close()
        except Exception as backup_error:
            st.error(f"Backup async execution also failed: {backup_error}")
            raise backup_error


def run_async_task_simple(coro):
    """
    ç®€å•çš„å¼‚æ­¥ä»»åŠ¡è¿è¡Œå™¨ï¼Œé¿å…å¤šçº¿ç¨‹é—®é¢˜ / Simple async task runner avoiding threading issues
    
    Args:
        coro: åç¨‹å¯¹è±¡ / Coroutine object
        
    Returns:
        ä»»åŠ¡ç»“æœ / Task result
    """
    # åº”ç”¨ nest_asyncio æ¥æ”¯æŒåµŒå¥—çš„äº‹ä»¶å¾ªç¯
    nest_asyncio.apply()
    
    try:
        # å°è¯•åœ¨å½“å‰äº‹ä»¶å¾ªç¯ä¸­è¿è¡Œ
        loop = asyncio.get_event_loop()
        if loop.is_running():
            # å¦‚æœå½“å‰å¾ªç¯æ­£åœ¨è¿è¡Œï¼Œåˆ›å»ºæ–°å¾ªç¯
            import concurrent.futures
            import threading
            
            def run_in_thread():
                new_loop = asyncio.new_event_loop()
                asyncio.set_event_loop(new_loop)
                try:
                    return new_loop.run_until_complete(coro)
                finally:
                    new_loop.close()
            
            with concurrent.futures.ThreadPoolExecutor(max_workers=1) as executor:
                future = executor.submit(run_in_thread)
                return future.result(timeout=300)  # 5åˆ†é’Ÿè¶…æ—¶
        else:
            # ç›´æ¥åœ¨å½“å‰å¾ªç¯ä¸­è¿è¡Œ
            return loop.run_until_complete(coro)
    except:
        # åˆ›å»ºæ–°çš„äº‹ä»¶å¾ªç¯
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        try:
            return loop.run_until_complete(coro)
        finally:
            loop.close()


def handle_processing_workflow(input_source: str, input_type: str) -> Dict[str, Any]:
    """
    å¤„ç†å·¥ä½œæµçš„ä¸»è¦å¤„ç†å‡½æ•° / Main processing function for workflow
    
    Args:
        input_source: è¾“å…¥æº / Input source
        input_type: è¾“å…¥ç±»å‹ / Input type
        
    Returns:
        å¤„ç†ç»“æœ / Processing result
    """
    from .components import (
        enhanced_progress_display_component, 
        update_step_indicator, 
        display_status,
        add_communication_message,
        set_communication_stage,
        create_persistent_processing_state,
        update_persistent_processing_state
    )
    
    # åˆ›å»ºä»»åŠ¡IDå’Œåˆå§‹åŒ–æŒä¹…åŒ–çŠ¶æ€
    task_id = str(uuid.uuid4())[:8]
    create_persistent_processing_state()
    
    # æ˜¾ç¤ºå¢å¼ºç‰ˆè¿›åº¦ç»„ä»¶
    progress_bar, status_text, step_indicators, workflow_steps, communication_container = enhanced_progress_display_component()
    
    # æ­¥éª¤æ˜ å°„ï¼šå°†è¿›åº¦ç™¾åˆ†æ¯”æ˜ å°„åˆ°æ­¥éª¤ç´¢å¼•
    step_mapping = {
        5: 0,   # Initialize
        10: 1,  # Analyze
        25: 2,  # Download
        45: 3,  # References
        50: 4,  # Plan
        60: 5,  # Repos
        70: 6,  # Index
        85: 7,  # Implement
        100: 7  # Complete
    }
    
    current_step = 0
    
    # å®šä¹‰å¢å¼ºç‰ˆè¿›åº¦å›è°ƒå‡½æ•° / Define enhanced progress callback function
    def update_progress(progress: int, message: str):
        nonlocal current_step
        
        # æ›´æ–°è¿›åº¦æ¡
        progress_bar.progress(progress)
        status_text.markdown(f"**{message}**")
        
        # ç¡®å®šå½“å‰æ­¥éª¤
        new_step = step_mapping.get(progress, current_step)
        if new_step != current_step:
            # å®Œæˆä¸Šä¸€ä¸ªé˜¶æ®µ
            if current_step >= 0:
                set_communication_stage(current_step, 'completed')
                add_communication_message(current_step, 'system_info', f"Stage completed: {workflow_steps[current_step][1]}")
            
            current_step = new_step
            update_step_indicator(step_indicators, workflow_steps, current_step, "active")
            
            # æ¿€æ´»æ–°é˜¶æ®µçš„é€šä¿¡çª—å£
            set_communication_stage(current_step, 'active')
            add_communication_message(current_step, 'system_info', f"Stage started: {workflow_steps[current_step][1]}")
        
        # æ›´æ–°æŒä¹…åŒ–çŠ¶æ€
        update_persistent_processing_state(task_id, 'running', progress, current_step, message)
        
        # æ·»åŠ è¿›åº¦æ¶ˆæ¯åˆ°å½“å‰é€šä¿¡çª—å£
        if current_step >= 0:
            add_communication_message(current_step, 'system_info', message)
        
        time.sleep(0.3)  # çŸ­æš‚åœé¡¿ä»¥ä¾¿ç”¨æˆ·çœ‹åˆ°è¿›åº¦å˜åŒ–
    
    # è‡ªå®šä¹‰è¿›åº¦å›è°ƒï¼ŒåŒ…å«Agent-LLMé€šä¿¡æ¨¡æ‹Ÿ
    def enhanced_update_progress(progress: int, message: str):
        update_progress(progress, message)
        
        # æ¨¡æ‹ŸAgentä¸LLMçš„å¯¹è¯
        stage_names = {
            0: "Initialization",
            1: "Analysis", 
            2: "Download",
            3: "References",
            4: "Planning", 
            5: "Repositories",
            6: "Indexing",
            7: "Implementation"
        }
        
        if current_step in stage_names:
            stage_name = stage_names[current_step]
            
            # æ¨¡æ‹ŸAgentè¯·æ±‚
            agent_requests = {
                0: "Initializing system components and loading AI models...",
                1: "Analyzing paper structure, extracting key concepts and methodologies...",
                2: "Processing document downloads and preparing file structures...", 
                3: "Examining references and building knowledge graph...",
                4: "Creating implementation plan based on paper findings...",
                5: "Searching and downloading relevant code repositories...",
                6: "Building comprehensive codebase index and relationships...",
                7: "Implementing code based on analysis and planning..."
            }
            
            llm_responses = {
                0: "System ready. Neural networks loaded. Proceeding with task initialization.",
                1: "Paper analysis complete. Identified key algorithms and implementation patterns.",
                2: "Document processing successful. File structure organized and ready.",
                3: "Reference analysis complete. Knowledge connections established.",
                4: "Implementation plan generated with detailed step-by-step approach.",
                5: "Repository search complete. Relevant codebases identified and downloaded.",
                6: "Codebase indexing complete. Dependencies and relationships mapped.",
                7: "Code implementation in progress. Following best practices and patterns."
            }
            
            if current_step in agent_requests:
                add_communication_message(current_step, 'agent_request', agent_requests[current_step])
                time.sleep(0.5)  # Small delay for realism
                add_communication_message(current_step, 'llm_response', llm_responses[current_step])
    
    # æ­¥éª¤1: åˆå§‹åŒ– / Step 1: Initialization
    enhanced_update_progress(5, "ğŸš€ Initializing AI research engine and loading models...")
    update_step_indicator(step_indicators, workflow_steps, 0, "active")
    
    # å¼€å§‹å¼‚æ­¥å¤„ç†ï¼Œä½¿ç”¨å¢å¼ºçš„è¿›åº¦å›è°ƒ
    with st.spinner("ğŸ”„ Processing workflow stages..."):
        try:
            # é¦–å…ˆå°è¯•ä½¿ç”¨ç®€å•çš„å¼‚æ­¥å¤„ç†æ–¹æ³•
            result = run_async_task_simple(process_input_async(input_source, input_type, enhanced_update_progress))
        except Exception as e:
            st.warning(f"Primary async method failed: {e}")
            # å¤‡ç”¨æ–¹æ³•ï¼šä½¿ç”¨åŸå§‹çš„çº¿ç¨‹æ± æ–¹æ³•
            try:
                result = run_async_task(process_input_async(input_source, input_type, enhanced_update_progress))
            except Exception as backup_error:
                st.error(f"Both async methods failed. Error: {backup_error}")
                # æ›´æ–°æŒä¹…åŒ–çŠ¶æ€ä¸ºé”™è¯¯
                update_persistent_processing_state(task_id, 'error', 0, current_step, f"Processing failed: {backup_error}")
                return {
                    "status": "error",
                    "error": str(backup_error),
                    "traceback": traceback.format_exc()
                }
    
    # æ ¹æ®ç»“æœæ›´æ–°æœ€ç»ˆçŠ¶æ€
    if result["status"] == "success":
        # å®Œæˆæ‰€æœ‰æ­¥éª¤
        enhanced_update_progress(100, "âœ… All processing stages completed successfully!")
        update_step_indicator(step_indicators, workflow_steps, len(workflow_steps), "completed")
        
        # å®Œæˆæœ€åä¸€ä¸ªé˜¶æ®µ
        if current_step >= 0:
            set_communication_stage(current_step, 'completed')
            add_communication_message(current_step, 'system_info', "ğŸ‰ All stages completed successfully!")
            add_communication_message(current_step, 'llm_response', "Task execution completed. All objectives achieved successfully.")
        
        # æ›´æ–°æŒä¹…åŒ–çŠ¶æ€ä¸ºå®Œæˆ
        update_persistent_processing_state(task_id, 'completed', 100, current_step, "Processing completed successfully!")
        
        # æ˜¾ç¤ºæˆåŠŸä¿¡æ¯
        st.balloons()  # æ·»åŠ åº†ç¥åŠ¨ç”»
        display_status("ğŸ‰ Workflow completed! Your research paper has been successfully processed and code has been generated.", "success")
        
    else:
        # å¤„ç†å¤±è´¥
        enhanced_update_progress(0, "âŒ Processing failed - see error details below")
        update_step_indicator(step_indicators, workflow_steps, current_step, "error")
        
        # åœ¨å½“å‰é˜¶æ®µæ·»åŠ é”™è¯¯ä¿¡æ¯
        if current_step >= 0:
            set_communication_stage(current_step, 'error')
            add_communication_message(current_step, 'system_info', f"âŒ Error occurred: {result.get('error', 'Unknown error')}")
        
        # æ›´æ–°æŒä¹…åŒ–çŠ¶æ€ä¸ºé”™è¯¯
        update_persistent_processing_state(task_id, 'error', 0, current_step, f"Processing failed: {result.get('error', 'Unknown error')}")
        
        display_status(f"âŒ Processing encountered an error: {result.get('error', 'Unknown error')}", "error")
    
    # ç­‰å¾…ä¸€ä¸‹è®©ç”¨æˆ·çœ‹åˆ°å®ŒæˆçŠ¶æ€
    time.sleep(2.5)
    
    return result


def update_session_state_with_result(result: Dict[str, Any], input_type: str):
    """
    ç”¨ç»“æœæ›´æ–°session state / Update session state with result
    
    Args:
        result: å¤„ç†ç»“æœ / Processing result
        input_type: è¾“å…¥ç±»å‹ / Input type
    """
    if result["status"] == "success":
        # ä¿å­˜ç»“æœåˆ°session state
        st.session_state.last_result = result
        st.session_state.show_results = True
        
        # ä¿å­˜åˆ°å†å²è®°å½•
        st.session_state.results.append({
            "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "input_type": input_type,
            "status": "success",
            "result": result
        })
    else:
        # ä¿å­˜é”™è¯¯ä¿¡æ¯åˆ°session stateç”¨äºæ˜¾ç¤º
        st.session_state.last_error = result.get("error", "Unknown error")
        
        # ä¿å­˜é”™è¯¯åˆ°å†å²è®°å½•
        st.session_state.results.append({
            "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "input_type": input_type,
            "status": "error",
            "error": result.get("error", "Unknown error")
        })
    
    # é™åˆ¶å†å²è®°å½•æœ€å¤šä¿å­˜50æ¡
    if len(st.session_state.results) > 50:
        st.session_state.results = st.session_state.results[-50:]


def cleanup_temp_file(input_source: str, input_type: str):
    """
    æ¸…ç†ä¸´æ—¶æ–‡ä»¶ / Cleanup temporary file
    
    Args:
        input_source: è¾“å…¥æº / Input source
        input_type: è¾“å…¥ç±»å‹ / Input type
    """
    if input_type == "file" and input_source and os.path.exists(input_source):
        try:
            os.unlink(input_source)
        except:
            pass


def handle_start_processing_button(input_source: str, input_type: str):
    """
    å¤„ç†å¼€å§‹å¤„ç†æŒ‰é’®ç‚¹å‡» / Handle start processing button click
    
    Args:
        input_source: è¾“å…¥æº / Input source
        input_type: è¾“å…¥ç±»å‹ / Input type
    """
    from .components import display_status
    
    st.session_state.processing = True
    
    # å¤„ç†å·¥ä½œæµ
    result = handle_processing_workflow(input_source, input_type)
    
    # æ˜¾ç¤ºç»“æœçŠ¶æ€
    if result["status"] == "success":
        display_status("All operations completed successfully! ğŸ‰", "success")
    else:
        display_status(f"Error during processing", "error")
    
    # æ›´æ–°session state
    update_session_state_with_result(result, input_type)
    
    # å¤„ç†å®Œæˆåé‡ç½®çŠ¶æ€
    st.session_state.processing = False
    
    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
    cleanup_temp_file(input_source, input_type)
    
    # é‡æ–°è¿è¡Œä»¥æ˜¾ç¤ºç»“æœæˆ–é”™è¯¯
    st.rerun()


def handle_error_display():
    """
    å¤„ç†é”™è¯¯æ˜¾ç¤º / Handle error display
    """
    if hasattr(st.session_state, 'last_error') and st.session_state.last_error:
        st.error(f"âŒ Error: {st.session_state.last_error}")
        if st.button("ğŸ”„ Try Again", type="secondary", use_container_width=True):
            st.session_state.last_error = None
            st.session_state.task_counter += 1
            st.rerun()


def initialize_session_state():
    """
    åˆå§‹åŒ–session state / Initialize session state
    """
    if 'processing' not in st.session_state:
        st.session_state.processing = False
    if 'results' not in st.session_state:
        st.session_state.results = []
    if 'current_step' not in st.session_state:
        st.session_state.current_step = 0
    if 'task_counter' not in st.session_state:
        st.session_state.task_counter = 0
    if 'show_results' not in st.session_state:
        st.session_state.show_results = False
    if 'last_result' not in st.session_state:
        st.session_state.last_result = None
    if 'last_error' not in st.session_state:
        st.session_state.last_error = None
    
    # æ–°å¢ï¼šé€šä¿¡çª—å£ç›¸å…³çŠ¶æ€
    if 'stage_communications' not in st.session_state:
        st.session_state.stage_communications = {}
    if 'current_communication_stage' not in st.session_state:
        st.session_state.current_communication_stage = -1
    
    # æ–°å¢ï¼šæŒä¹…åŒ–å¤„ç†çŠ¶æ€
    if 'persistent_task_id' not in st.session_state:
        st.session_state.persistent_task_id = None
    if 'persistent_task_status' not in st.session_state:
        st.session_state.persistent_task_status = 'idle'
    if 'persistent_task_progress' not in st.session_state:
        st.session_state.persistent_task_progress = 0
    if 'persistent_task_stage' not in st.session_state:
        st.session_state.persistent_task_stage = -1
    if 'persistent_task_message' not in st.session_state:
        st.session_state.persistent_task_message = ""
    if 'task_start_time' not in st.session_state:
        st.session_state.task_start_time = None 